{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e5UW0DRIONXm"
      },
      "source": [
        "Escolha da task na pasta Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JW5kRK34cn5-"
      },
      "outputs": [],
      "source": [
        "TASK = 'assin-ptpt-rte'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oPmiM3DpM9oD"
      },
      "source": [
        "Baixar o repositório do mt-dnn e requisitos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "xMnlg408Sryq",
        "outputId": "c196ad81-1b8b-4dbc-d084-d5da12b5c903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mt-dnn'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 1577 (delta 172), reused 244 (delta 151), pack-reused 1288\u001b[K\n",
            "Receiving objects: 100% (1577/1577), 970.00 KiB | 4.31 MiB/s, done.\n",
            "Resolving deltas: 100% (861/861), done.\n",
            "/content/drive/My Drive/html/assin-ptpt-rte/mt-dnn\n",
            "Collecting pytorch_pretrained_bert==0.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/1a/1d94d7725825d6c6796da00b9ad5c875eab69c15bc8ffd0d1588b83600bc/pytorch_pretrained_bert-0.5.1-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (4.28.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (1.4.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.5.1) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.5.1) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.5.1) (1.14.15)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert==0.5.1) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert==0.5.1) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert==0.5.1) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.5.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.17.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=f7e4a8034595e06a40b3505ba1ae2b61fbe4967866f7554444048fe956662df3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.2.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/namisan/mt-dnn\n",
        "%cd mt-dnn \n",
        "!git checkout 60aa9dc4ec1\n",
        "!pip install pytorch_pretrained_bert==0.5.1\n",
        "!pip install sentencepiece \n",
        "!pip install seqeval  \n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WZAaz77LXbuH"
      },
      "source": [
        "Baixar modelos de rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "rSo5ITaKXPCL",
        "outputId": "e9f0392a-e4e0-4348-99be-1f612227485b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  xlnet_cased_large.zip\n",
            "   creating: xlnet_cased_L-24_H-1024_A-16/\n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.index  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.data-00000-of-00001  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/spiece.model  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.meta  \n",
            "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_config.json  \n",
            "roberta.base/\n",
            "roberta.base/dict.txt\n",
            "roberta.base/model.pt\n",
            "roberta.base/NOTE\n",
            "roberta.large/\n",
            "roberta.large/dict.txt\n",
            "roberta.large/model.pt\n",
            "roberta.large/NOTE\n",
            "Archive:  SciTailV1.1.zip\n",
            "   creating: SciTailV1.1/\n",
            "   creating: SciTailV1.1/snli_format/\n",
            "  inflating: SciTailV1.1/snli_format/scitail_1.0_test.txt  \n",
            "  inflating: SciTailV1.1/snli_format/scitail_1.0_train.txt  \n",
            "  inflating: SciTailV1.1/snli_format/scitail_1.0_dev.txt  \n",
            "  inflating: SciTailV1.1/snli_format/README.txt  \n",
            "   creating: SciTailV1.1/dgem_format/\n",
            "  inflating: SciTailV1.1/dgem_format/scitail_1.0_structure_dev.tsv  \n",
            "  inflating: SciTailV1.1/dgem_format/scitail_1.0_structure_train.tsv  \n",
            "  inflating: SciTailV1.1/dgem_format/README.txt  \n",
            "  inflating: SciTailV1.1/dgem_format/scitail_1.0_structure_test.tsv  \n",
            "   creating: SciTailV1.1/predictor_format/\n",
            "  inflating: SciTailV1.1/predictor_format/scitail_1.0_structure_dev.jsonl  \n",
            "  inflating: SciTailV1.1/predictor_format/scitail_1.0_structure_test.jsonl  \n",
            "  inflating: SciTailV1.1/predictor_format/README.txt  \n",
            "  inflating: SciTailV1.1/predictor_format/scitail_1.0_structure_train.jsonl  \n",
            "  inflating: SciTailV1.1/all_annotations.tsv  \n",
            "  inflating: SciTailV1.1/README.txt  \n",
            "   creating: SciTailV1.1/tsv_format/\n",
            "  inflating: SciTailV1.1/tsv_format/scitail_1.0_test.tsv  \n",
            "  inflating: SciTailV1.1/tsv_format/scitail_1.0_train.tsv  \n",
            "  inflating: SciTailV1.1/tsv_format/scitail_1.0_dev.tsv  \n",
            "Create a folder /content/drive/My Drive/html/assin-ptpt-rte/mt-dnn/data\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/scitail_001_train.json  \n",
            "  inflating: data/scitail_01_train.json  \n",
            "  inflating: data/scitail_1_train.json  \n",
            "  inflating: data/scitail_5_train.json  \n",
            "  inflating: data/scitail_dev.json   \n",
            "  inflating: data/scitail_test.json  \n",
            "  inflating: data/scitail_train.json  \n",
            "  inflating: data/scitail_train_shuff.json  \n",
            "  inflating: data/snli_001_train.json  \n",
            "  inflating: data/snli_01_train.json  \n",
            "  inflating: data/snli_1_train.json  \n",
            "  inflating: data/snli_5_train.json  \n",
            "  inflating: data/snli_dev.json      \n",
            "  inflating: data/snli_test.json     \n",
            "  inflating: data/snli_train.json    \n",
            "  inflating: data/snli_train_shuff.json  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#When mount on Google Drive on Colab, please run download.sh until it downloads mt_dnn_base_uncased.pt\n",
        "#Or run !bash ../download_model.sh that it will do it for you\n",
        "!bash download.sh"
        
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1-fM4MYkgMOn"
      },
      "source": [
        "Mover dados da task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "colab_type": "code",
        "id": "uwRXdwqbUiSf",
        "outputId": "5a813e20-c414-43e5-a281-8626b17ee350"
      },
      "outputs": [],
      "source": [
        "!mkdir data/canonical_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p8lcS5hvEukx"
      },
      "source": [
        "Aplicar patch em metrics.py para incluir *f1_nomean* e *mse*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "p4bxREiEE1i1",
        "outputId": "ecd4653c-d4b6-4dd4-d2b6-66e080c1072c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "patching file data_utils/metrics.py\n"
          ]
        }
      ],
      "source": [
        "!patch data_utils/metrics.py < ../metrics.patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2NaWGK-XM6c"
      },
      "source": [
        "Mover dados de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BdQftgD0XSZZ"
      },
      "outputs": [],
      "source": [
        "%mv ../move_input.sh move_input.sh\n",
        "!bash move_input.sh $TASK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDbJogORhthT"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "colab_type": "code",
        "id": "kW44tIeHYHjK",
        "outputId": "8df852f3-b36f-4064-c4cc-6f6bcc38c31b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "03/07/2020 03:11:35 Task assin-ptpt-rte\n",
            "03/07/2020 03:11:35 data/canonical_data/bert_uncased_lower/assin-ptpt-rte_train.json\n",
            "03/07/2020 03:11:36 data/canonical_data/bert_uncased_lower/assin-ptpt-rte_dev.json\n",
            "03/07/2020 03:11:36 data/canonical_data/bert_uncased_lower/assin-ptpt-rte_test.json\n"
          ]
        }
      ],
      "source": [
        "!python prepro_std.py --do_lower_case --root_dir data/canonical_data --task_def {TASK}.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnizDq8DQx3L",
        "colab_type": "text"
      },
      "source": [
        "Habilitar scores dos datasets de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08uCBhGGQ6i0",
        "colab_type": "code",
        "outputId": "5f99e43f-2dbd-4f17-c991-371e1f2b671d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!patch train.py < ../train.patch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patching file train.py\n",
            "Reversed (or previously applied) patch detected!  Assume -R? [n] \n",
            "Apply anyway? [n] \n",
            "Skipping patch.\n",
            "1 out of 1 hunk ignored -- saving rejects to file train.py.rej\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnizDq7DQx3L",
        "colab_type": "text"
      },
      "source": [
        "Corrigir mt_dnn/model.py e prepro_std.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08uCBhAGQ6i0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!patch mt_dnn/model.py < ../model.patch\n",
        "!patch prepro_std.py < ../prepro_std.patch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9BqM241CjFBQ"
      },
      "source": [
        "Train task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "G7DAoFbjYxZK",
        "outputId": "2582773e-c940-4713-e71d-7cb9c1081727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Namespace(adam_eps=1e-06, answer_att_hidden_size=128, answer_att_type='bilinear', answer_dropout_p=0.1, answer_mem_drop_p=0.1, answer_mem_type=1, answer_merge_opt=1, answer_num_turn=5, answer_opt=0, answer_rnn_type='gru', answer_sum_att_type='bilinear', answer_weight_norm_on=False, batch_size=8, batch_size_eval=8, bert_dropout_p=0.1, bert_l2norm=0.0, bert_model_type='bert-base-uncased', cuda=False, data_dir='data/canonical_data/bert_uncased_lower', data_sort_on=False, do_lower_case=True, dropout_p=0.1, dropout_w=0.0, dump_state_on=False, embedding_opt=0, encoder_type=<EncoderModelType.BERT: 1>, epochs=5, fp16=False, fp16_opt_level='O1', freeze_layers=-1, global_grad_clipping=1.0, glue_format_on=False, grad_accumulation_step=1, grad_clipping=0, have_lr_scheduler=True, init_checkpoint='mt_dnn_models/mt_dnn_base_uncased.pt', init_ratio=1, label_size='3', learning_rate=5e-05, log_file='mt-dnn-train.log', log_per_updates=500, lr_gamma=0.5, masked_lm_prob=0.15, max_answer_len=5, max_predictions_per_seq=128, max_seq_len=512, mem_cum_type='simple', mix_opt=0, model_ckpt='checkpoints/model_0.pt', momentum=0, mtl_opt=0, multi_gpu_on=False, multi_step_lr='10,20,30', name='farmer', optimizer='adamax', output_dir='checkpoint', ratio=0, resume=False, save_per_updates=10000, save_per_updates_on=False, scheduler_type='ms', seed=2018, short_seq_prob=0.2, task_def='assin-ptpt-rte.yaml', tensorboard=True, tensorboard_logdir='tensorboard_logdir', test_datasets=['assin-ptpt-rte'], train_datasets=['assin-ptpt-rte'], update_bert_opt=0, vb_dropout=True, warmup=0.1, warmup_schedule='warmup_linear', weight_decay=0)\n",
            "03/07/2020 03:11:45 0\n",
            "03/07/2020 03:11:45 Launching the MT-DNN training\n",
            "03/07/2020 03:11:45 Loading data/canonical_data/bert_uncased_lower/assin-ptpt-rte_train.json as task 0\n",
            "Loaded 2500 samples out of 2500\n",
            "03/07/2020 03:11:45 3\n",
            "Loaded 500 samples out of 500\n",
            "Loaded 2000 samples out of 2000\n",
            "03/07/2020 03:11:45 ####################\n",
            "03/07/2020 03:11:45 {'log_file': 'mt-dnn-train.log', 'tensorboard': True, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'mt_dnn_models/mt_dnn_base_uncased.pt', 'data_dir': 'data/canonical_data/bert_uncased_lower', 'data_sort_on': False, 'name': 'farmer', 'task_def': 'assin-ptpt-rte.yaml', 'train_datasets': ['assin-ptpt-rte'], 'test_datasets': ['assin-ptpt-rte'], 'glue_format_on': False, 'update_bert_opt': 0, 'multi_gpu_on': False, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 5, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': [0], 'label_size': '3', 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': <EncoderModelType.BERT: 1>, 'bert_model_type': 'bert-base-uncased', 'do_lower_case': True, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'cuda': False, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 5, 'batch_size': 8, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'freeze_layers': -1, 'embedding_opt': 0, 'lr_gamma': 0.5, 'bert_l2norm': 0.0, 'scheduler_type': 'ms', 'output_dir': 'checkpoint', 'seed': 2018, 'grad_accumulation_step': 1, 'fp16': False, 'fp16_opt_level': 'O1', 'task_types': [<TaskType.Classification: 1>], 'tasks_dropout_p': [0.03], 'loss_types': [<LossCriterion.CeCriterion: 0>], 'kd_loss_types': [None]}\n",
            "03/07/2020 03:11:45 ####################\n",
            "03/07/2020 03:11:45 ############# Gradient Accumulation Info #############\n",
            "03/07/2020 03:11:45 number of step: 1565\n",
            "03/07/2020 03:11:45 number of grad grad_accumulation step: 1\n",
            "03/07/2020 03:11:45 adjusted number of step: 1565\n",
            "03/07/2020 03:11:45 ############# Gradient Accumulation Info #############\n",
            "03/07/2020 03:11:45 ####################\n",
            "03/07/2020 03:11:45 Could not find the init model!\n",
            " The parameters will be initialized randomly!\n",
            "03/07/2020 03:11:45 ####################\n",
            "03/07/2020 03:11:47 \n",
            "############# Model Arch of MT-DNN #############\n",
            "SANBertNetwork(\n",
            "  (dropout_list): ModuleList(\n",
            "    (0): DropoutWrapper()\n",
            "  )\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): BertLayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (scoring_list): ModuleList(\n",
            "    (0): Linear(in_features=768, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "03/07/2020 03:11:47 Total number of params: 109484547\n",
            "03/07/2020 03:11:47 At epoch 0\n",
            "03/07/2020 03:11:58 Task [ 0] updates[     1] train loss[1.15553] remaining[0:54:35]\n"
          ]
        }
      ],
      "source": [
        "!python train.py --do_lower_case --init_checkpoint mt_dnn_models/mt_dnn_base_uncased.pt --task_def {TASK}.yaml --train_datasets {TASK} --test_datasets {TASK} --tensorboard --data_dir data/canonical_data/bert_base_uncased_lower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuhUcumffS3m",
        "colab_type": "text"
      },
      "source": [
        "Mostrar resultados do *train.py* para arquivos de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNEzOC_efbGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c61daa0-5db5-43b6-f27c-5f89d86d2f48"
      },
      "source": [
        "import json\n",
        "\n",
        "filepath = 'checkpoint/{}_test_scores_4.json'.format(TASK) \n",
        "with open(filepath) as f:\n",
        "    scores = json.load(f)\n",
        "\n",
        "print(scores['metrics'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Pearson': 85.01105592648992, 'MSE': 13.714753768382353}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJXnJpHu8c-I",
        "colab_type": "text"
      },
      "source": [
        "Abrir *Tensorboard*.\n",
        "\n",
        "Executa no *Chrome* normalmente, mas não funciona no *Firefox*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrdIcUv89EmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard  --logdir tensorboard_logdir"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
