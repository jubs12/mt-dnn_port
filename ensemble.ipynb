{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWc_ZDwjEPDL",
        "colab_type": "code",
        "outputId": "20143cf5-4b6c-4f54-8de6-1b4f06f08ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!git clone https://github.com/jubs12/mt-dnn_port.git -b seed\n",
        "%cd mt-dnn_port"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mt-dnn_port'...\n",
            "remote: Enumerating objects: 8652, done.\u001b[K\n",
            "remote: Counting objects: 100% (8652/8652), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7856/7856), done.\u001b[K\n",
            "remote: Total 63042 (delta 1234), reused 8082 (delta 743), pack-reused 54390\u001b[K\n",
            "Receiving objects: 100% (63042/63042), 493.87 MiB | 23.16 MiB/s, done.\n",
            "Resolving deltas: 100% (26338/26338), done.\n",
            "Checking out files: 100% (27943/27943), done.\n",
            "/content/mt-dnn_port\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKiKj6rrRmbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mode = 'st-dnn/assin2-sts'\n",
        "pretrained = 'bert_base'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfK2QO-XR0_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import copy\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "prefix = f'output/{mode}/{pretrained}'\n",
        "\n",
        "seeds_dir = f'{prefix}/seed'\n",
        "seeds = os.listdir(seeds_dir)\n",
        "sample_seed = seeds[0]\n",
        "\n",
        "grad_norm_seed_sample_dir = f'{seeds_dir}/{sample_seed}/grad_norm/'\n",
        "grad_norms = os.listdir(grad_norm_seed_sample_dir)\n",
        "sample_grad_norm = grad_norms[0]\n",
        "\n",
        "dropout_grad_norm_seed_sample_dir =  \\\n",
        "    f'{seeds_dir}/{sample_seed}/grad_norm/{sample_grad_norm}/dropout/'\n",
        "dropouts = os.listdir(dropout_grad_norm_seed_sample_dir)\n",
        "sample_dropout = dropouts[0]\n",
        "\n",
        "\n",
        "datasets = [f for f in os.listdir(f\"{grad_norm_seed_sample_dir}/{sample_grad_norm}\") \n",
        "            if f.endswith('test_scores_4.json')] \n",
        "\n",
        "output_dir = prefix + '/ensemble/'\n",
        "\n",
        "cabezudo = [\n",
        "            'best-pt',\n",
        "            'random-pt',\n",
        "            'worst-pt',\n",
        "            'assin1-rte'\n",
        "]\n",
        "\n",
        "def is_rte(dataset: str) -> bool:\n",
        "    rte_on_name = dataset.endswith('rte_test_scores_4.json')\n",
        "    is_cabezudo = dataset in cabezudo\n",
        "\n",
        "    return rte_on_name or is_cabezudo\n",
        "\n",
        "def get_key(dataset: str) -> str:\n",
        "    key = 'predictions' if is_rte(dataset) else 'scores'\n",
        "    return key\n",
        "\n",
        "def get_info(dataset: str, seed: str, grad_norm: str, dropout: str) -> dict:\n",
        "    filename = f'{prefix}/seed/{seed}/grad_norm/{grad_norm}/dropout/{dropout}/{dataset}'\n",
        "\n",
        "    with open(filename) as f:\n",
        "        info = json.load(f)\n",
        "\n",
        "    return info\n",
        "\n",
        "def average_score(dataset: str, info_lst: list) -> list:\n",
        "    scores_lst = [info[get_key(dataset)] for info in info_lst]\n",
        "\n",
        "    scores_arr = np.array(scores_lst)\n",
        "    scores_avg = stats.mode(scores_arr, axis=0).mode[0] if is_rte(dataset) \\\n",
        "                else np.mean(scores_arr, axis=0)\n",
        "    scores_avg = scores_avg.tolist()\n",
        "    assert len(scores_avg) == len(scores_lst[0])\n",
        "\n",
        "    return scores_avg\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "for dataset in datasets:\n",
        "    info_lst = [get_info(dataset, seed, grad_norm, dropout) \n",
        "                for seed in seeds for grad_norm in grad_norms for dropout in dropouts]\n",
        "    \n",
        "    ensemble = copy.deepcopy(get_info(dataset, sample_seed, sample_grad_norm, sample_dropout))\n",
        "    ensemble[get_key(dataset)] = average_score(dataset, info_lst)\n",
        "\n",
        "    with open(f'{output_dir}/{dataset}', 'w') as f:\n",
        "        json.dump(ensemble, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}