{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assin2tsv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQqi9oPu3F0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLDER = '../data/dataset'\n",
        "INPUT_PT = '../data/input/pt'\n",
        "INPUT_EN = '../data/input/en'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTMo3bsyQJea"
      },
      "source": [
        "Get dataset and requirement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOa1JXb1PAFO",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Q9j1a83CuKzsHCGaNulSkNxBm7Dkn7Ln' -O assin2-train-only.xml\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1J3FpQaHxpM-FDfBUyooh-sZF-B-bM_lU' -O assin2-test.xml\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kb7xq6Mb3eaqe9cOAo70BaG9ypwkIqEU' -O assin2-dev.xml\n",
        "!wget http://nilc.icmc.usp.br/assin/assin.tar.gz\n",
        "\n",
        "!tar -xzf assin.tar.gz\n",
        "%rm -rf assin.tar.gz\n",
        "\n",
        "!pip install xmltodict\n",
        "\n",
        "%mkdir $FOLDER\n",
        "%mv *.xml $FOLDER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pGk_NBOcQPu8"
      },
      "source": [
        "Import xml files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SisZe9vQQzC3",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import xmltodict\n",
        "import os\n",
        "import re\n",
        "\n",
        "files_xml = [f for f in os.listdir(FOLDER) if 'xml' in f]\n",
        "names = list()\n",
        "xmls = list()\n",
        "\n",
        "for filename in files_xml:\n",
        "    with open(f'{FOLDER}/{filename}') as f:\n",
        "        xml = xmltodict.parse(f.read())\n",
        "        name = re.sub(r'(.*).xml', r'\\1', filename)\n",
        "        xmls.append(xml)\n",
        "        names.append(name)\n",
        "\n",
        "xml_names = dict(zip(names, xmls))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dnj_eNGDJHdP"
      },
      "source": [
        "Generate tsv in Portuguese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VduSnluFx4tG",
        "colab": {}
      },
      "source": [
        "header = ['id', 'label','premise', 'hipothesis']\n",
        "output_names = []\n",
        "output_files = []\n",
        "for name in names:\n",
        "    place = xml_names[name]['entailment-corpus']['pair'] \n",
        "\n",
        "    if 'only' in name:\n",
        "        name = name.replace('-only', '')\n",
        "\n",
        "    output_names.append(re.sub(r'(.+)-(.+)', r'\\1-rte_\\2', name))\n",
        "    output_names.append(re.sub(r'(.+)-(.+)', r'\\1-sts_\\2', name))\n",
        "    rte = list()\n",
        "    sts = list()\n",
        "\n",
        "    for idx, item in enumerate(place):\n",
        "        rte.append((item['@id'],item['@entailment'],item['t'],item['h']))\n",
        "        sts.append((item['@id'],item['@similarity'],item['t'],item['h']))\n",
        "\n",
        "    rte_df = pd.DataFrame(rte, index = None, columns = header)\n",
        "    sts_df = pd.DataFrame(sts, index = None, columns = header)\n",
        "\n",
        "    output_files.append(rte_df)\n",
        "    output_files.append(sts_df)\n",
        "\n",
        "for idx, output in enumerate(output_files):\n",
        "    output_name = f'{INPUT_PT}/{output_names[idx]}.tsv'\n",
        "    output.to_csv(output_name, sep = '\\t', index = False, header = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUCN3jYoJPPm"
      },
      "source": [
        "Get Portuguese inputs dictionary and translation dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HovibZUL4lT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "23187e98-49a7-4fc2-f44e-08a2755d797f"
      },
      "source": [
        "table_dict = dict(zip(output_names, output_files))\n",
        "!wget https://raw.githubusercontent.com/ruanchaves/assin/master/sources/dictionary.json -O assin-dic.json\n",
        "\n",
        "import json\n",
        "\n",
        "with open('assin-dic.json') as json_file:\n",
        "    translation = json.load(json_file)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-17 16:09:21--  https://raw.githubusercontent.com/ruanchaves/assin/master/sources/dictionary.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4322760 (4.1M) [text/plain]\n",
            "Saving to: ‘assin-dic.json’\n",
            "\n",
            "\rassin-dic.json        0%[                    ]       0  --.-KB/s               \rassin-dic.json      100%[===================>]   4.12M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-04-17 16:09:21 (40.8 MB/s) - ‘assin-dic.json’ saved [4322760/4322760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFkdn1_bOu1h"
      },
      "source": [
        "Map Portuguese to English and Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YMTo6gH8Obk_",
        "colab": {}
      },
      "source": [
        "for key in table_dict.keys():\n",
        "    for col in ['premise', 'hipothesis']:\n",
        "        table_dict[key][col] = table_dict[key][col].map(translation)\n",
        "\n",
        "    output_name = f'{INPUT_EN}/{output_names[idx]}.tsv'\n",
        "    table_dict[key].to_csv(output_name, sep = '\\t', index = False, header = None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDnjk3UczAJC",
        "colab_type": "text"
      },
      "source": [
        "Remove HTML marks from translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Tvc7VczAJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e7477dc6-17de-4aa0-bf61-ace48c07b606"
      },
      "source": [
        "!pip install ftfy\n",
        "%cp  ftfy_assin.sh {INPUT_EN}/ftfy_assin.sh\n",
        "%cd $INPUT_EN\n",
        "!bash ftfy_assin.sh\n",
        "%rm -f /ftfy_assin.sh "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (5.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.9)\n",
            "/content/mt-dnn_port/mt-dnn_port/data/input/en\n",
            "./assin2-rte_train.tsv\n",
            "./assin-ptbr-rte_train.tsv\n",
            "./assin-ptpt-sts_test.tsv\n",
            "./assin-ptpt-rte_dev.tsv\n",
            "./assin2-rte_dev.tsv\n",
            "./assin-ptbr-rte_dev.tsv\n",
            "./assin2-sts_dev.tsv\n",
            "./assin2-sts_test.tsv\n",
            "./assin-ptpt-rte_train.tsv\n",
            "./assin-ptpt-sts_dev.tsv\n",
            "./assin2-rte_test.tsv\n",
            "./assin-ptbr-sts_test.tsv\n",
            "./assin-ptbr-rte_test.tsv\n",
            "./assin-ptbr-sts_dev.tsv\n",
            "./assin-ptpt-sts_train.tsv\n",
            "./assin-ptbr-sts_train.tsv\n",
            "./assin-ptpt-rte_test.tsv\n",
            "./assin2-sts_train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBFzmLjfQe1c",
        "colab_type": "text"
      },
      "source": [
        "Remove quotes incorrect in *assin-ptbr-train* line 1711 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHJVJPHQQeOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filepath in ['assin-ptbr-rte_train.tsv', 'assin-ptbr-sts_train.tsv']:\n",
        "    with open(filepath, 'r') as f:\n",
        "        corpus = f.read()\n",
        "        corpus = corpus.replace('\"As long as','As long as')\n",
        "\n",
        "    with open(filepath, 'w') as f:   \n",
        "        f.write(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}