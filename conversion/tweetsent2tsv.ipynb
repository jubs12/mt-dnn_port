{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweetsent2tsv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uL3E0DLC6zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLDER = '../data/dataset'\n",
        "INPUT_PT = '../data/input/pt'\n",
        "INPUT_EN = '../data/input/en'\n",
        "DICT_PATH = '../translate'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8jKJ0NsMony",
        "colab_type": "text"
      },
      "source": [
        "Extract dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8-hVAaLYrT",
        "colab_type": "code",
        "outputId": "ec496139-a1ee-427d-f48f-dc0a3211d6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!unzip tweetSentBR_extracted.zip"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tweetSentBR_extracted.zip\n",
            "   creating: tweetSentBR_extracted/\n",
            "  inflating: tweetSentBR_extracted/testTT.neg  \n",
            "  inflating: tweetSentBR_extracted/testTT.neu  \n",
            "  inflating: tweetSentBR_extracted/testTT.pos  \n",
            "  inflating: tweetSentBR_extracted/trainTT.neg  \n",
            "  inflating: tweetSentBR_extracted/trainTT.neu  \n",
            "  inflating: tweetSentBR_extracted/trainTT.pos  \n",
            "  inflating: tweetSentBR_extracted/tweets.none  \n",
            "  inflating: tweetSentBR_extracted/tweets.neg  \n",
            "  inflating: tweetSentBR_extracted/tweets.neu  \n",
            "  inflating: tweetSentBR_extracted/tweets.pos  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHNw9Oh-TR47",
        "colab_type": "text"
      },
      "source": [
        "Separate files in tab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wZIV1BdMzzO",
        "colab_type": "code",
        "outputId": "f7a7fba0-9c0e-4eab-8e93-1f561f60a566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "folder = 'tweetSentBR_extracted'\n",
        "corpus = [f for f in os.listdir(folder) if 'TT' in f and not 'tab' in f]\n",
        "\n",
        "for split in corpus:\n",
        "    print(split)\n",
        "    with open(f'{folder}/{split}') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    assert '\\t' not in text \n",
        "    \n",
        "    outtext = re.sub(r'(.+?) (.+)',r'\\1\\t\\2', text)\n",
        "    outfile = re.sub(r'(.+)\\.(.+)', r'\\1_tab.\\2',split)\n",
        "    with open(f'{folder}/{outfile}', 'w') as f:\n",
        "        f.write(outtext)\n",
        "        print(f'{folder}/{outfile}')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testTT.pos\n",
            "tweetSentBR_extracted/testTT_tab.pos\n",
            "trainTT.pos\n",
            "tweetSentBR_extracted/trainTT_tab.pos\n",
            "trainTT.neu\n",
            "tweetSentBR_extracted/trainTT_tab.neu\n",
            "trainTT.neg\n",
            "tweetSentBR_extracted/trainTT_tab.neg\n",
            "testTT.neg\n",
            "tweetSentBR_extracted/testTT_tab.neg\n",
            "testTT.neu\n",
            "tweetSentBR_extracted/testTT_tab.neu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcheMTZgUFjJ",
        "colab_type": "text"
      },
      "source": [
        "Generate tsv in Portuguese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjb5rkvuqvSL",
        "colab_type": "code",
        "outputId": "a2a7ba2e-ba20-4811-a9d6-42155340df9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "splits = {\n",
        "    'train' : [f for f in os.listdir(folder) if 'train' in f and 'tab' in f],\n",
        "    'test'  : [f for f in os.listdir(folder) if 'test' in f and 'tab' in f],\n",
        "}\n",
        "\n",
        "header = ['id', 'premise']\n",
        "\n",
        "abbr = {\n",
        "    'neg': 'Negative', \n",
        "    'neu': 'Neutral',\n",
        "    'pos': 'Positive',\n",
        "} \n",
        "\n",
        "output_header = ['id', 'label', 'premise']\n",
        "\n",
        "for name, files in splits.items():\n",
        "\n",
        "    output = pd.DataFrame()\n",
        "    for f in files:\n",
        "        filepath = f'{folder}/{f}'\n",
        "        table = pd.read_csv(filepath, index_col = None, sep = '\\t', names = header)\n",
        "\n",
        "        posfix = f.split('.')[1]\n",
        "        label = abbr[posfix]\n",
        "        table['label'] = label\n",
        "\n",
        "        output = table if output.empty else output.append(table)\n",
        "\n",
        "    output = output.reindex(columns = output_header)\n",
        "    output = output.sample(frac = 1)\n",
        "    \n",
        "    outpath = f'{INPUT_PT}/tweetsent_{name}.tsv'\n",
        "    output.to_csv(outpath, index = None, header = None, sep = '\\t')\n",
        "\n",
        "    print(outpath)\n",
        "    print('{} tweets\\n'.format(output.shape[0]))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../data/input/pt/tweetsent_train.tsv\n",
            "10980 tweets\n",
            "\n",
            "../data/input/pt/tweetsent_test.tsv\n",
            "2010 tweets\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WivxrhwDBe3K",
        "colab_type": "text"
      },
      "source": [
        "Generate tsv in English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siZLi_JI7Zad",
        "colab_type": "code",
        "outputId": "14849199-82a0-4dbb-a09f-b1ad9e2e5988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import json\n",
        "\n",
        "files = [f for f in os.listdir(INPUT_PT) if 'tweetsent' in f]\n",
        "\n",
        "with open(f'{DICT_PATH}/tweetsent-dic.json') as f:\n",
        "    translation = json.load(f)\n",
        "\n",
        "for file in files:\n",
        "    filepath = f'{INPUT_PT}/{file}'\n",
        "    table = pd.read_csv(filepath, names = output_header, header = None, sep = '\\t')\n",
        "    table['premise'] = table['premise'].map(translation)\n",
        "    \n",
        "    outpath = filepath.replace(INPUT_PT, INPUT_EN)\n",
        "    table.to_csv(outpath, index = None, sep = '\\t', header = None)\n",
        "    \n",
        "    print(outpath)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../data/input/en/tweetsent_test.tsv\n",
            "../data/input/en/tweetsent_train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDnjk3UczAJC",
        "colab_type": "text"
      },
      "source": [
        "Remove HTML marks from translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Tvc7VczAJD",
        "colab_type": "code",
        "outputId": "271ce5b8-1539-4918-9345-9e35ebac22ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "!pip install ftfy\n",
        "%cp  fix_html.sh {INPUT_EN}/\n",
        "%cd $INPUT_EN\n",
        "!bash fix_html.sh\n",
        "%rm -f fix_html.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (5.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.9)\n",
            "/content/mt-dnn_port/data/input/en\n",
            "./assin2-rte_train.tsv\n",
            "./assin-ptbr-rte_train.tsv\n",
            "./assin-ptpt-sts_test.tsv\n",
            "./assin-ptpt-rte_dev.tsv\n",
            "./assin2-rte_dev.tsv\n",
            "./assin-ptbr-rte_dev.tsv\n",
            "./assin2-sts_dev.tsv\n",
            "./assin2-sts_test.tsv\n",
            "./tweetsent_test.tsv\n",
            "./assin-ptpt-rte_train.tsv\n",
            "./assin-ptpt-sts_dev.tsv\n",
            "./assin2-rte_test.tsv\n",
            "./assin-ptbr-sts_test.tsv\n",
            "./assin-ptbr-rte_test.tsv\n",
            "./assin-ptbr-sts_dev.tsv\n",
            "./assin-ptpt-sts_train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}