{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweetsent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8jKJ0NsMony",
        "colab_type": "text"
      },
      "source": [
        "Extrair *dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8-hVAaLYrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "77f1238e-30f4-4fef-fe96-9a949225db70"
      },
      "source": [
        "!unzip tweetSentBR_extracted.zip\n",
        "%cd tweetSentBR_extracted"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tweetSentBR_extracted.zip\n",
            "   creating: tweetSentBR_extracted/\n",
            "  inflating: tweetSentBR_extracted/testTT.neg  \n",
            "  inflating: tweetSentBR_extracted/testTT.neu  \n",
            "  inflating: tweetSentBR_extracted/testTT.pos  \n",
            "  inflating: tweetSentBR_extracted/trainTT.neg  \n",
            "  inflating: tweetSentBR_extracted/trainTT.neu  \n",
            "  inflating: tweetSentBR_extracted/trainTT.pos  \n",
            "  inflating: tweetSentBR_extracted/tweets.none  \n",
            "  inflating: tweetSentBR_extracted/tweets.neg  \n",
            "  inflating: tweetSentBR_extracted/tweets.neu  \n",
            "  inflating: tweetSentBR_extracted/tweets.pos  \n",
            "/content/tweetSentBR_extracted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHNw9Oh-TR47",
        "colab_type": "text"
      },
      "source": [
        "Ler arquivos e separar por tab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wZIV1BdMzzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a12e7f78-b852-4abc-fca8-02764bf2b57d"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "corpus = [f for f in os.listdir(os.curdir) if 'tweets' in f and not 'tab' in f]\n",
        "\n",
        "for filepath in corpus:\n",
        "    with open(filepath) as f:\n",
        "        text = f.read()\n",
        "\n",
        "    assert '\\t' not in text \n",
        "    \n",
        "    outtext = re.sub(r'(.+?) (.+)',r'\\1\\t\\2', text)\n",
        "    outpath = re.sub(r'(.+)\\.(.+)', r'\\1_tab.\\2',filepath)\n",
        "    with open(outpath, 'w') as f:\n",
        "        f.write(outtext)\n",
        "        print(outpath)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweets_tab.pos\n",
            "tweets_tab.neu\n",
            "tweets_tab.none\n",
            "tweets_tab.neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcheMTZgUFjJ",
        "colab_type": "text"
      },
      "source": [
        "Gerar lista de sentenças para serem traduzidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP_RYLJT6K9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c806d996-86ea-4c89-b3b4-4e0741566fe9"
      },
      "source": [
        "tabbed = [f for f in os.listdir(os.curdir) if 'tab' in f]\n",
        "header = ['id', 'text']\n",
        "\n",
        "sentences = set()\n",
        "for f in tabbed:\n",
        "    table = pd.read_csv(f, index_col = None, sep = '\\t', names = header)\n",
        "    sentences |= set(table['text'])\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(sentences)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twNAkGlfbF9i",
        "colab_type": "text"
      },
      "source": [
        "Definir o código de tradução"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgRx5LogWmjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import translate_v2 as translate\n",
        "from os.path import isfile\n",
        "from os import environ\n",
        "import six\n",
        "import json\n",
        "\n",
        "def translate2dict(sentences, dictpath):\n",
        "    environ['GOOGLE_APPLICATION_CREDENTIALS'] = './key.json'\n",
        "    translate_client = translate.Client()\n",
        "\n",
        "    def translation(text):\n",
        "        if isinstance(text, six.binary_type):\n",
        "            text = text.decode('utf-8')\n",
        "        result = translate_client.translate(text,'en')\n",
        "\n",
        "        return result['translatedText']\n",
        "\n",
        "    if not isfile(dictpath):\n",
        "        with open(dictpath, 'w') as f:\n",
        "            json.dump({}, f)\n",
        "\n",
        "    for item in sentences:\n",
        "        with open(dictpath) as f:\n",
        "            translations = json.load(f)\n",
        "        \n",
        "        try:\n",
        "            translations[item]\n",
        "        except KeyError:\n",
        "            translations[item] = translation(item)\n",
        "            \n",
        "            with open(dictpath, 'w+') as f:\n",
        "                json.dump(translations, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTHWr2hxc1zL",
        "colab_type": "text"
      },
      "source": [
        "Traduzir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_37CSlRc0_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictpath = 'tweetsent-dic.json'\n",
        "translate2dict(sentences, dictpath)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
