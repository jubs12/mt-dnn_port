Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  84.25%	   0.621

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.762		              0.36


Saved evaluation: report/st-dnn/bert_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  85.20%	   0.745

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.780		              0.65


Saved evaluation: report/st-dnn/bert_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.89%	   0.868

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.821		              0.66


Saved evaluation: report/st-dnn/bert_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7015
F1. neg: 0.686 neu: 0.575 post: 0.789
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.1015
Acc dist max equal: 0.1905

Saved evaluation: report/st-dnn/bert_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.75%	   0.743

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.779		              0.33


Saved evaluation: report/mt-dnn_assin/bert_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.65%	   0.775

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.801		              0.54


Saved evaluation: report/mt-dnn_assin/bert_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.66%	   0.876

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.822		              0.60


Saved evaluation: report/mt-dnn_assin/bert_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.45%	   0.742

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.770		              0.33


Saved evaluation: report/mt-dnn_assin+tweetsent/bert_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.65%	   0.781

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.798		              0.51


Saved evaluation: report/mt-dnn_assin+tweetsent/bert_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.30%	   0.872

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.822		              0.59


Saved evaluation: report/mt-dnn_assin+tweetsent/bert_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7040
F1. neg: 0.681 neu: 0.582 post: 0.790
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.1015
Acc dist max equal: 0.1905

Saved evaluation: report/mt-dnn_assin+tweetsent/bert_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.05%	   0.542

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.793		              0.30


Saved evaluation: report/st-dnn/bert_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.50%	   0.776

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.801		              0.54


Saved evaluation: report/st-dnn/bert_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.73%	   0.887

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.838		              0.56


Saved evaluation: report/st-dnn/bert_large/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7154
F1. neg: 0.693 neu: 0.609 post: 0.794
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0965
Acc dist max equal: 0.1955

Saved evaluation: report/st-dnn/bert_large/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.50%	   0.755

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.814		              0.28


Saved evaluation: report/mt-dnn_assin/bert_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.40%	   0.814

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.825		              0.48


Saved evaluation: report/mt-dnn_assin/bert_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.13%	   0.891

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.835		              0.50


Saved evaluation: report/mt-dnn_assin/bert_large/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.75%	   0.757

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.807		              0.28


Saved evaluation: report/mt-dnn_assin+tweetsent/bert_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.70%	   0.816

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.817		              0.47


Saved evaluation: report/mt-dnn_assin+tweetsent/bert_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.93%	   0.889

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.835		              0.52


Saved evaluation: report/mt-dnn_assin+tweetsent/bert_large/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7289
F1. neg: 0.712 neu: 0.599 post: 0.815
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0940
Acc dist max equal: 0.1980

Saved evaluation: report/mt-dnn_assin+tweetsent/bert_large/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.00%	   0.796

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.811		              0.27


Saved evaluation: report/st-dnn/mt-dnn_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.85%	   0.843

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.822		              0.45


Saved evaluation: report/st-dnn/mt-dnn_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.67%	   0.896

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.850		              0.48


Saved evaluation: report/st-dnn/mt-dnn_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7149
F1. neg: 0.702 neu: 0.587 post: 0.800
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0930
Acc dist max equal: 0.1990

Saved evaluation: report/st-dnn/mt-dnn_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.70%	   0.799

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.816		              0.27


Saved evaluation: report/mt-dnn_assin/mt-dnn_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.80%	   0.825

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.835		              0.41


Saved evaluation: report/mt-dnn_assin/mt-dnn_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.44%	   0.904

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.844		              0.49


Saved evaluation: report/mt-dnn_assin/mt-dnn_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.15%	   0.809

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.810		              0.28


Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.30%	   0.825

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.830		              0.43


Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.69%	   0.907

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.846		              0.46


Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7144
F1. neg: 0.705 neu: 0.585 post: 0.799
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0896
Acc dist max equal: 0.2025

Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.60%	   0.820

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.833		              0.24


Saved evaluation: report/st-dnn/mt-dnn_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.95%	   0.837

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.839		              0.43


Saved evaluation: report/st-dnn/mt-dnn_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.05%	   0.910

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.854		              0.46


Saved evaluation: report/st-dnn/mt-dnn_large/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7214
F1. neg: 0.701 neu: 0.586 post: 0.815
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0930
Acc dist max equal: 0.1990

Saved evaluation: report/st-dnn/mt-dnn_large/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.45%	   0.838

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.838		              0.25


Saved evaluation: report/mt-dnn_assin/mt-dnn_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.40%	   0.842

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.847		              0.44


Saved evaluation: report/mt-dnn_assin/mt-dnn_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.09%	   0.911

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.850		              0.47


Saved evaluation: report/mt-dnn_assin/mt-dnn_large/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.80%	   0.847

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.831		              0.26


Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.05%	   0.844

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.849		              0.44


Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.60%	   0.906

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.851		              0.49


Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_large/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7229
F1. neg: 0.708 neu: 0.592 post: 0.811
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0905
Acc dist max equal: 0.2015

Saved evaluation: report/mt-dnn_assin+tweetsent/mt-dnn_large/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.60%	   0.774

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.834		              0.27


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.75%	   0.824

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.841		              0.56


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.70%	   0.877

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.833		              0.64


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7373
F1. neg: 0.734 neu: 0.609 post: 0.816
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0776
Acc dist max equal: 0.2144

Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.95%	   0.812

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.840		              0.24


Saved evaluation: report/mt-dnn_assin/bert-pt_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.10%	   0.854

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.855		              0.40


Saved evaluation: report/mt-dnn_assin/bert-pt_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.52%	   0.905

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.847		              0.52


Saved evaluation: report/mt-dnn_assin/bert-pt_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.50%	   0.822

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.831		              0.25


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.45%	   0.854

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.857		              0.40


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.48%	   0.905

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.843		              0.53


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7408
F1. neg: 0.730 neu: 0.618 post: 0.822
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0826
Acc dist max equal: 0.2095

Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.90%	   0.792

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.849		              0.23


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.70%	   0.845

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.859		              0.44


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.13%	   0.891

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.858		              0.45


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7602
F1. neg: 0.753 neu: 0.632 post: 0.838
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0736
Acc dist max equal: 0.2184

Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  93.05%	   0.847

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.861		              0.20


Saved evaluation: report/mt-dnn_assin/bert-pt_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  93.25%	   0.876

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.866		              0.40


Saved evaluation: report/mt-dnn_assin/bert-pt_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.93%	   0.909

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.858		              0.45


Saved evaluation: report/mt-dnn_assin/bert-pt_large/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.95%	   0.851

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.861		              0.21


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.90%	   0.865

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.863		              0.41


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_large/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.85%	   0.908

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.859		              0.46


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_large/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.7612
F1. neg: 0.761 neu: 0.623 post: 0.839
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0731
Acc dist max equal: 0.2189

Saved evaluation: report/mt-dnn_assin+tweetsent/bert-pt_large/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.60%	   0.778

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.826		              0.28


Saved evaluation: report/mt-dnn_assin-ptbr+assin2/bert-pt_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.97%	   0.890

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.837		              0.55


Saved evaluation: report/mt-dnn_assin-ptbr+assin2/bert-pt_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.67%	   0.896

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.845		              0.55


Saved evaluation: report/mt-dnn_assin2/bert-pt_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.30%	   0.825

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.854		              0.24


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-1+2/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.05%	   0.852

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.859		              0.46


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-1+2/assin-ptpt_eval.txt
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.32%	   0.903

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.843		              0.56


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-1+2/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.25%	   0.787

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.841		              0.27


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-ptbr+2/assin-ptbr_eval.txt
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.36%	   0.903

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.839		              0.62


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin-ptbr+2/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.00%	   0.821

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.853		              0.22


Saved evaluation: report/mt-dnn_assin-ptbr+assin2/bert-pt_large/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.97%	   0.910

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.858		              0.45


Saved evaluation: report/mt-dnn_assin-ptbr+assin2/bert-pt_large/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.60%	   0.906

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.858		              0.47


Saved evaluation: report/mt-dnn_assin2/bert-pt_large/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.50%	   0.801

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.866		              0.20


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-1+2/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  92.00%	   0.839

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.871		              0.40


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-1+2/assin-ptpt_eval.txt
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.87%	   0.898

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.857		              0.43


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-1+2/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.40%	   0.716

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.859		              0.21


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-ptbr+2/assin-ptbr_eval.txt
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.67%	   0.896

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.859		              0.44


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin-ptbr+2/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.70%	   0.755

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.815		              0.27


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.15%	   0.808

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.838		              0.45


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  85.95%	   0.859

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.816		              0.54


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.6965
F1. neg: 0.672 neu: 0.559 post: 0.793
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.0955
Acc dist max equal: 0.1965

Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.80%	   0.781

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.810		              0.27


Saved evaluation: report/mt-dnn_assin/bert-multilingual_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.60%	   0.819

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.837		              0.44


Saved evaluation: report/mt-dnn_assin/bert-multilingual_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.46%	   0.874

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.813		              0.59


Saved evaluation: report/mt-dnn_assin/bert-multilingual_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.70%	   0.774

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.810		              0.28


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-multilingual_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.10%	   0.827

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.837		              0.44


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-multilingual_base/seed/2017/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.01%	   0.870

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.811		              0.57


Saved evaluation: report/mt-dnn_assin+tweetsent/bert-multilingual_base/seed/2017/assin2_eval.txt
Saving generated JSON...
corpus: TweetSentBR
Acc: 0.6846
F1. neg: 0.648 neu: 0.559 post: 0.783
Acc dist min: 0.2920
Acc dist max: 0.2920
Acc dist min equal: 0.1109
Acc dist max equal: 0.1811

Saved evaluation: report/mt-dnn_assin+tweetsent/bert-multilingual_base/seed/2017/tweetsent_eval.txt

Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.70%	   0.749

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.800		              0.30


Saved evaluation: report/mt-dnn_assin-ptbr+assin2/bert-multilingual_base/seed/2017/assin-ptbr_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.52%	   0.885

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.817		              0.53


Saved evaluation: report/mt-dnn_assin-ptbr+assin2/bert-multilingual_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.50%	   0.875

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.815		              0.57


Saved evaluation: report/mt-dnn_assin2/bert-multilingual_base/seed/2017/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.40%	   0.800

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.826		              0.25


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-1+2/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.30%	   0.835

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.845		              0.44


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-1+2/assin-ptpt_eval.txt
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.25%	   0.872

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.828		              0.48


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-1+2/assin2_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.40%	   0.706

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.814		              0.27


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-ptbr+2/assin-ptbr_eval.txt
corpus: assin2

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.25%	   0.872

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  0.828		              0.50


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin-ptbr+2/assin2_eval.txt
