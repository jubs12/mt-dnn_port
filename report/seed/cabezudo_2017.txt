Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.95%	   0.796

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin1-rte/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.55%	   0.819

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/assin1-rte/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.25%	   0.725

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/best-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.85%	   0.781

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/best-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.00%	   0.714

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/random-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.60%	   0.776

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/random-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.80%	   0.710

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/worst-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.45%	   0.772

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2017/worst-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.85%	   0.794

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin1-rte/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.30%	   0.840

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/assin1-rte/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.85%	   0.763

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/best-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.25%	   0.788

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/best-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.95%	   0.765

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/random-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.80%	   0.777

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/random-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.55%	   0.746

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/worst-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.10%	   0.779

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2017/worst-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.55%	   0.696

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin1-rte/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.60%	   0.748

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/assin1-rte/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.70%	   0.708

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/best-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.45%	   0.753

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/best-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.30%	   0.696

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/random-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.55%	   0.746

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/random-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.40%	   0.708

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/worst-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.75%	   0.751

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2017/worst-pt/assin-ptpt_eval.txt
