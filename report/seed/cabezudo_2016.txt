Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.55%	   0.776

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/assin1-rte/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.75%	   0.812

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/assin1-rte/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.50%	   0.722

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/best-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.90%	   0.788

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/best-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.65%	   0.724

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/random-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.30%	   0.789

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/random-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.35%	   0.718

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/worst-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.00%	   0.784

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_base/seed/2016/worst-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.55%	   0.814

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/assin1-rte/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  91.05%	   0.829

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/assin1-rte/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.65%	   0.757

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/best-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.45%	   0.785

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/best-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.90%	   0.757

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/random-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  88.90%	   0.772

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/random-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  90.00%	   0.764

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/worst-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  89.50%	   0.789

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-pt_large/seed/2016/worst-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.65%	   0.551

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/assin1-rte/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.85%	   0.570

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/assin1-rte/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.95%	   0.714

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/best-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.25%	   0.741

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/best-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.00%	   0.707

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/random-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.20%	   0.734

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/random-pt/assin-ptpt_eval.txt
Saving generated XMLs...
corpus: assin-ptbr

RTE evaluation
Accuracy	Macro F1
--------	--------
  87.25%	   0.714

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/worst-pt/assin-ptbr_eval.txt
corpus: assin-ptpt

RTE evaluation
Accuracy	Macro F1
--------	--------
  86.60%	   0.749

Similarity evaluation
Pearson		Mean Squared Error
-------		------------------
  1.000		              0.00


Saved evaluation: report/st-dnn/bert-multilingual_base/seed/2016/worst-pt/assin-ptpt_eval.txt

