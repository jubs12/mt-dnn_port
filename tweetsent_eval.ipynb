{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_benchmarks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3wy72h_Xxzq",
        "colab_type": "text"
      },
      "source": [
        "Baixar repositório *script* de avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njm6ce3AXZKb",
        "colab_type": "code",
        "outputId": "96ac0df4-eb30-4929-b43d-d7899298c0ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!git clone https://bitbucket.org/HBrum/tweetsentbr.git\n",
        "%cd tweetsentbr/sent-analysis/\n",
        "!pip install nlpnet"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tweetsentbr'...\n",
            "remote: Counting objects: 85, done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 85 (delta 20), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n",
            "/content/tweetsentbr/sent-analysis/mt-dnn_port/Training/tweetsent/tweetsentbr/sent-analysis\n",
            "Requirement already satisfied: nlpnet in /usr/local/lib/python3.6/dist-packages (1.2.4)\n",
            "Requirement already satisfied: h5py>=2.8.0rc1 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (2.8.0)\n",
            "Requirement already satisfied: nltk>=3.2.2 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (3.2.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from nlpnet) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qfvPEMWHcWS",
        "colab_type": "text"
      },
      "source": [
        "Extrair arquivos de avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dP93RTlHb8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "70752e04-8354-46be-e4ec-4a64f8708a8e"
      },
      "source": [
        "!unzip tweetSentBR_extracted.zip"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tweetSentBR_extracted.zip\n",
            "   creating: tweetSentBR_extracted/\n",
            "  inflating: tweetSentBR_extracted/testTT.neg  \n",
            "  inflating: tweetSentBR_extracted/testTT.neu  \n",
            "  inflating: tweetSentBR_extracted/testTT.pos  \n",
            "  inflating: tweetSentBR_extracted/trainTT.neg  \n",
            "  inflating: tweetSentBR_extracted/trainTT.neu  \n",
            "  inflating: tweetSentBR_extracted/trainTT.pos  \n",
            "  inflating: tweetSentBR_extracted/tweets.none  \n",
            "  inflating: tweetSentBR_extracted/tweets.neg  \n",
            "  inflating: tweetSentBR_extracted/tweets.neu  \n",
            "  inflating: tweetSentBR_extracted/tweets.pos  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vD1fIF4ZGQl",
        "colab_type": "text"
      },
      "source": [
        "Obter arquivo com resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUgmYv5DY-MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = '../../results/results.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unEhXl4ADKnS",
        "colab_type": "text"
      },
      "source": [
        "Gerar arquivo único de teste separado por tabulação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub5WCk-dDPs4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1ca7e94c-1549-49fe-eb16-f271c4e070ce"
      },
      "source": [
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "corpora = [f for f in os.listdir('tweetSentBR_extracted') if 'testTT' in f]\n",
        "\n",
        "print('Separando as colunas por tabulação...')\n",
        "tabbed = dict()\n",
        "for goldpath in corpora:\n",
        "    with open(\"tweetSentBR_extracted/{}\".format(goldpath)) as f:\n",
        "        text = f.read()\n",
        "\n",
        "    assert '\\t' not in text \n",
        "    \n",
        "    outtext = re.sub(r'(.+?) (.+)',r'\\1\\t\\2', text)\n",
        "    tabbed.update({goldpath:StringIO(outtext)})\n",
        "    print(goldpath)\n",
        "    \n",
        "print('Unificando os arquivos..')\n",
        "\n",
        "header = ['id', 'premise']\n",
        "abbr = {'neg': 'Negative', 'neu': 'Neutral', 'pos': 'Positive'} \n",
        "output = pd.DataFrame()\n",
        "\n",
        "for path, f in tabbed.items():\n",
        "    table = pd.read_csv(f, sep = '\\t', names = header)\n",
        "\n",
        "    posfix = path.split('.')[1]\n",
        "    label = abbr[posfix]\n",
        "    table['label'] = label\n",
        "\n",
        "    output = table if output.empty else output.append(table)\n",
        "\n",
        "output.to_csv('tweetsentbr_test.csv', index = None)\n",
        "print('tweetsentbr_test.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Separando as colunas por tabulação...\n",
            "testTT.neu\n",
            "testTT.neg\n",
            "testTT.pos\n",
            "Unificando os arquivos..\n",
            "tweetsentbr_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5y45Z35FMks",
        "colab_type": "text"
      },
      "source": [
        "Gerar *scores*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfFBDHbCZI5y",
        "colab_type": "code",
        "outputId": "2eca2a58-a71b-45da-fb31-5c38441408f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from classify import report\n",
        "import pandas as pd\n",
        "\n",
        "corpus  = pd.read_csv('tweetsentbr_test.csv')\n",
        "result = pd.read_csv(filepath)\n",
        "\n",
        "distances = result['distances']\n",
        "number = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
        "predictions = result['predictions'].map(number)\n",
        "\n",
        "y_test = list()\n",
        "for result_idx, result_row in result.iterrows():\n",
        "    uid = result_row['TweetID']\n",
        "    corpus_row  = corpus.loc[corpus['id'] == uid]\n",
        "    y = corpus_row.iloc[0]['label']\n",
        "    y_test.append(number[y])\n",
        "\n",
        "report(distances, predictions, y_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.7119\n",
            "F1. neg: 0.703 neu: 0.585 post: 0.792\n",
            "Acc dist min: 0.0000\n",
            "Acc dist max: 0.0000\n",
            "Acc dist min equal: 0.0000\n",
            "Acc dist max equal: 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:61: FutureWarning: \n",
            "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
            "instead.\n",
            "The behavior of 'argmin' will be corrected to return the positional\n",
            "minimum in the future. For now, use 'series.values.argmin' or\n",
            "'np.argmin(np.array(values))' to get the position of the minimum\n",
            "row.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:61: FutureWarning: \n",
            "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
            "instead.\n",
            "The behavior of 'argmax' will be corrected to return the positional\n",
            "maximum in the future. For now, use 'series.values.argmax' or\n",
            "'np.argmax(np.array(values))' to get the position of the maximum\n",
            "row.\n",
            "  return bound(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}