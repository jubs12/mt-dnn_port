{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e5UW0DRIONXm"
      },
      "source": [
        "Choose TASK, MODEL and TYPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JW5kRK34cn5-",
        "colab": {}
      },
      "source": [
        "TASK = 'tweetsent'\n",
        "MODEL = 'bert'\n",
        "TYPE = 'large'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oPmiM3DpM9oD"
      },
      "source": [
        "Get mt-dnn repo and requirements needed for colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xMnlg408Sryq",
        "outputId": "ec776a86-d98d-49a1-df88-159461eb45dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/namisan/mt-dnn\n",
        "%cd mt-dnn \n",
        "!git checkout 60aa9dc4ec1\n",
        "!pip install pytorch_pretrained_bert==0.5.1\n",
        "!pip install sentencepiece \n",
        "!pip install seqeval  \n",
        "!pip install tensorboardX\n",
        "!pip install transformers"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mt-dnn'...\n",
            "remote: Enumerating objects: 551, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/551)\u001b[K\rremote: Counting objects:   1% (6/551)\u001b[K\rremote: Counting objects:   2% (12/551)\u001b[K\rremote: Counting objects:   3% (17/551)\u001b[K\rremote: Counting objects:   4% (23/551)\u001b[K\rremote: Counting objects:   5% (28/551)\u001b[K\rremote: Counting objects:   6% (34/551)\u001b[K\rremote: Counting objects:   7% (39/551)\u001b[K\rremote: Counting objects:   8% (45/551)\u001b[K\rremote: Counting objects:   9% (50/551)\u001b[K\rremote: Counting objects:  10% (56/551)\u001b[K\rremote: Counting objects:  11% (61/551)\u001b[K\rremote: Counting objects:  12% (67/551)\u001b[K\rremote: Counting objects:  13% (72/551)\u001b[K\rremote: Counting objects:  14% (78/551)\u001b[K\rremote: Counting objects:  15% (83/551)\u001b[K\rremote: Counting objects:  16% (89/551)\u001b[K\rremote: Counting objects:  17% (94/551)\u001b[K\rremote: Counting objects:  18% (100/551)\rremote: Counting objects:  19% (105/551)\u001b[K\rremote: Counting objects:  20% (111/551)\u001b[K\rremote: Counting objects:  21% (116/551)\u001b[K\rremote: Counting objects:  22% (122/551)\u001b[K\rremote: Counting objects:  23% (127/551)\u001b[K\rremote: Counting objects:  24% (133/551)\u001b[K\rremote: Counting objects:  25% (138/551)\u001b[K\rremote: Counting objects:  26% (144/551)\u001b[K\rremote: Counting objects:  27% (149/551)\u001b[K\rremote: Counting objects:  28% (155/551)\u001b[K\rremote: Counting objects:  29% (160/551)\u001b[K\rremote: Counting objects:  30% (166/551)\u001b[K\rremote: Counting objects:  31% (171/551)\u001b[K\rremote: Counting objects:  32% (177/551)\u001b[K\rremote: Counting objects:  33% (182/551)\u001b[K\rremote: Counting objects:  34% (188/551)\u001b[K\rremote: Counting objects:  35% (193/551)\u001b[K\rremote: Counting objects:  36% (199/551)\u001b[K\rremote: Counting objects:  37% (204/551)\u001b[K\rremote: Counting objects:  38% (210/551)\u001b[K\rremote: Counting objects:  39% (215/551)\u001b[K\rremote: Counting objects:  40% (221/551)\u001b[K\rremote: Counting objects:  41% (226/551)\u001b[K\rremote: Counting objects:  42% (232/551)\u001b[K\rremote: Counting objects:  43% (237/551)\u001b[K\rremote: Counting objects:  44% (243/551)\u001b[K\rremote: Counting objects:  45% (248/551)\u001b[K\rremote: Counting objects:  46% (254/551)\u001b[K\rremote: Counting objects:  47% (259/551)\u001b[K\rremote: Counting objects:  48% (265/551)\u001b[K\rremote: Counting objects:  49% (270/551)\u001b[K\rremote: Counting objects:  50% (276/551)\u001b[K\rremote: Counting objects:  51% (282/551)\u001b[K\rremote: Counting objects:  52% (287/551)\u001b[K\rremote: Counting objects:  53% (293/551)\u001b[K\rremote: Counting objects:  54% (298/551)\u001b[K\rremote: Counting objects:  55% (304/551)\u001b[K\rremote: Counting objects:  56% (309/551)\u001b[K\rremote: Counting objects:  57% (315/551)\u001b[K\rremote: Counting objects:  58% (320/551)\u001b[K\rremote: Counting objects:  59% (326/551)\u001b[K\rremote: Counting objects:  60% (331/551)\u001b[K\rremote: Counting objects:  61% (337/551)\u001b[K\rremote: Counting objects:  62% (342/551)\u001b[K\rremote: Counting objects:  63% (348/551)\u001b[K\rremote: Counting objects:  64% (353/551)\u001b[K\rremote: Counting objects:  65% (359/551)\u001b[K\rremote: Counting objects:  66% (364/551)\u001b[K\rremote: Counting objects:  67% (370/551)\u001b[K\rremote: Counting objects:  68% (375/551)\u001b[K\rremote: Counting objects:  69% (381/551)\u001b[K\rremote: Counting objects:  70% (386/551)\u001b[K\rremote: Counting objects:  71% (392/551)\u001b[K\rremote: Counting objects:  72% (397/551)\u001b[K\rremote: Counting objects:  73% (403/551)\u001b[K\rremote: Counting objects:  74% (408/551)\u001b[K\rremote: Counting objects:  75% (414/551)\u001b[K\rremote: Counting objects:  76% (419/551)\u001b[K\rremote: Counting objects:  77% (425/551)\u001b[K\rremote: Counting objects:  78% (430/551)\u001b[K\rremote: Counting objects:  79% (436/551)\u001b[K\rremote: Counting objects:  80% (441/551)\u001b[K\rremote: Counting objects:  81% (447/551)\u001b[K\rremote: Counting objects:  82% (452/551)\u001b[K\rremote: Counting objects:  83% (458/551)\u001b[K\rremote: Counting objects:  84% (463/551)\u001b[K\rremote: Counting objects:  85% (469/551)\u001b[K\rremote: Counting objects:  86% (474/551)\u001b[K\rremote: Counting objects:  87% (480/551)\u001b[K\rremote: Counting objects:  88% (485/551)\u001b[K\rremote: Counting objects:  89% (491/551)\u001b[K\rremote: Counting objects:  90% (496/551)\u001b[K\rremote: Counting objects:  91% (502/551)\u001b[K\rremote: Counting objects:  92% (507/551)\u001b[K\rremote: Counting objects:  93% (513/551)\u001b[K\rremote: Counting objects:  94% (518/551)\u001b[K\rremote: Counting objects:  95% (524/551)\u001b[K\rremote: Counting objects:  96% (529/551)\u001b[K\rremote: Counting objects:  97% (535/551)\u001b[K\rremote: Counting objects:  98% (540/551)\u001b[K\rremote: Counting objects:  99% (546/551)\u001b[K\rremote: Counting objects: 100% (551/551)\u001b[K\rremote: Counting objects: 100% (551/551), done.\u001b[K\n",
            "remote: Compressing objects: 100% (323/323), done.\u001b[K\n",
            "remote: Total 2132 (delta 259), reused 467 (delta 212), pack-reused 1581\u001b[K\n",
            "Receiving objects: 100% (2132/2132), 1.70 MiB | 5.08 MiB/s, done.\n",
            "Resolving deltas: 100% (1152/1152), done.\n",
            "/content/mt-dnn_port/mt-dnn\n",
            "Note: checking out '60aa9dc4ec1'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 60aa9dc support F1 mac/mic\n",
            "Requirement already satisfied: pytorch_pretrained_bert==0.5.1 in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (1.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.5.1) (1.12.39)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.5.1) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.5.1) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.5.1) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.5.1) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert==0.5.1) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert==0.5.1) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert==0.5.1) (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.1.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p8lcS5hvEukx"
      },
      "source": [
        "Apply patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p4bxREiEE1i1",
        "outputId": "ed498ad8-2664-45be-bcb7-a91517120ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!patch data_utils/metrics.py < ../utils/patch/metrics.patch\n",
        "!patch mt_dnn/model.py < ../utils/patch/model.patch\n",
        "!patch prepro_std.py < ../utils/patch/prepro_std.patch\n",
        "!patch train.py < ../utils/patch/train.patch"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patching file data_utils/metrics.py\n",
            "patching file mt_dnn/model.py\n",
            "patching file prepro_std.py\n",
            "patching file train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziGIwDVeVftT",
        "colab_type": "text"
      },
      "source": [
        "Get spefics args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xJOZjclLxFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from subprocess import run\n",
        "\n",
        "INPUT_EN = \"../data/input/en\"\n",
        "INPUT_PT = \"../data/input/pt\"\n",
        "\n",
        "PREPRO_BERT = f\"--do_lower_case --root_dir {INPUT_EN} --model bert-{TYPE}-uncased\"\n",
        "PREPRO_MULTILINGUAL = f\"--model bert-{TYPE}-multilingual-cased --root_dir {INPUT_PT}\"\n",
        "PREPRO_BERT_PT = f\"--model neuralmind/bert-{TYPE}-portuguese-cased --root_dir {INPUT_PT}\"\n",
        "\n",
        "TRAIN_MT_DNN = f\"--init_checkpoint mt_dnn_models/mt_dnn_{TYPE}_uncased.pt \\\n",
        "              --data_dir {INPUT_EN}/bert_{TYPE}_uncased_lower/\"\n",
        "\n",
        "TRAIN_BERT = f\"--init_checkpoint bert-{TYPE}-uncased \\\n",
        "               --data_dir {INPUT_EN}/bert_{TYPE}_uncased_lower/\"\n",
        "\n",
        "TRAIN_MULTILINGUAL = f\"--data_dir  {INPUT_PT}/bert_{TYPE}_cased \\\n",
        "                  --init_checkpoint bert-{TYPE}-multilingual-cased\"\n",
        "\n",
        "TRAIN_BERT_PT = f\"--data_dir  {INPUT_PT}/bert_{TYPE}_cased \\\n",
        "                  --init_checkpoint neuralmind/bert-{TYPE}-portuguese-cased\"\n",
        "\n",
        "if  MODEL == \"bert\":\n",
        "   PREPRO = PREPRO_BERT\n",
        "   TRAIN = TRAIN_BERT\n",
        "elif MODEL ==  \"mt-dnn\":\n",
        "   print(\"running mt-dnn download script ...wait\")\n",
        "   run([\"bash\", \"download.sh\"])\n",
        "   PREPRO = PREPRO_BERT\n",
        "   TRAIN = TRAIN_MT_DNN\n",
        "elif MODEL == \"bert-pt\":\n",
        "   PREPRO = PREPRO_BERT_PT\n",
        "   TRAIN = TRAIN_BERT_PT\n",
        "elif MODEL == \"bert-multilingual\":\n",
        "   PREPRO = PREPRO_MULTILINGUAL\n",
        "   TRAIN = TRAIN_MULTILINGUAL\n",
        "else:\n",
        "  raise ValueError('Invalid model option')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDbJogORhthT"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kW44tIeHYHjK",
        "outputId": "15fdc023-7735-4952-83ba-061c4e6b3735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python prepro_std.py --task_def ../data/task-def/{TASK}.yaml {PREPRO}\n",
        "!python train.py  --task_def ../data/task-def/{TASK}.yaml --train_datasets {TASK} --test_datasets {TASK} --tensorboard {TRAIN}"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "2020-04-17 19:01:33.835918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "04/17/2020 07:01:35 Task tweetsent\n",
            "04/17/2020 07:01:35 ../data/input/en/bert_base_uncased_lower/tweetsent_train.json\n",
            "04/17/2020 07:01:39 ../data/input/en/bert_base_uncased_lower/tweetsent_test.json\n",
            "2020-04-17 19:01:42.272396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "Namespace(adam_eps=1e-06, answer_att_hidden_size=128, answer_att_type='bilinear', answer_dropout_p=0.1, answer_mem_drop_p=0.1, answer_mem_type=1, answer_merge_opt=1, answer_num_turn=5, answer_opt=0, answer_rnn_type='gru', answer_sum_att_type='bilinear', answer_weight_norm_on=False, batch_size=8, batch_size_eval=8, bert_dropout_p=0.1, bert_l2norm=0.0, bert_model_type='bert-base-uncased', cuda=False, data_dir='../data/input/en/bert_base_uncased_lower/', data_sort_on=False, do_lower_case=False, dropout_p=0.1, dropout_w=0.0, dump_state_on=False, embedding_opt=0, encode_mode=False, encoder_type=<EncoderModelType.BERT: 1>, epochs=5, fp16=False, fp16_opt_level='O1', freeze_layers=-1, global_grad_clipping=1.0, glue_format_on=False, grad_accumulation_step=1, grad_clipping=0, have_lr_scheduler=True, init_checkpoint='bert-base-uncased', init_ratio=1, learning_rate=5e-05, log_file='mt-dnn-train.log', log_per_updates=500, lr_gamma=0.5, masked_lm_prob=0.15, max_answer_len=5, max_predictions_per_seq=128, max_seq_len=512, mem_cum_type='simple', mix_opt=0, mkd_opt=0, model_ckpt='checkpoints/model_0.pt', momentum=0, mtl_opt=0, multi_gpu_on=False, multi_step_lr='10,20,30', name='farmer', num_hidden_layers=-1, optimizer='adamax', output_dir='checkpoint', ratio=0, resume=False, save_per_updates=10000, save_per_updates_on=False, scheduler_type='ms', seed=2018, short_seq_prob=0.2, task_def='../data/task-def/tweetsent.yaml', tensorboard=True, tensorboard_logdir='tensorboard_logdir', test_datasets=['tweetsent'], train_datasets=['tweetsent'], update_bert_opt=0, vb_dropout=True, warmup=0.1, warmup_schedule='warmup_linear', weight_decay=0)\n",
            "04/17/2020 07:01:44 0\n",
            "04/17/2020 07:01:44 Launching the MT-DNN training\n",
            "04/17/2020 07:01:44 Loading ../data/input/en/bert_base_uncased_lower/tweetsent_train.json as task 0\n",
            "Loaded 10980 samples out of 10980\n",
            "Loaded 2010 samples out of 2010\n",
            "04/17/2020 07:01:44 ####################\n",
            "04/17/2020 07:01:44 {'log_file': 'mt-dnn-train.log', 'tensorboard': True, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'bert-base-uncased', 'data_dir': '../data/input/en/bert_base_uncased_lower/', 'data_sort_on': False, 'name': 'farmer', 'task_def': '../data/task-def/tweetsent.yaml', 'train_datasets': ['tweetsent'], 'test_datasets': ['tweetsent'], 'glue_format_on': False, 'mkd_opt': 0, 'update_bert_opt': 0, 'multi_gpu_on': False, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 5, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': 0, 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': <EncoderModelType.BERT: 1>, 'num_hidden_layers': -1, 'bert_model_type': 'bert-base-uncased', 'do_lower_case': False, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'cuda': False, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 5, 'batch_size': 8, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'freeze_layers': -1, 'embedding_opt': 0, 'lr_gamma': 0.5, 'bert_l2norm': 0.0, 'scheduler_type': 'ms', 'output_dir': 'checkpoint', 'seed': 2018, 'grad_accumulation_step': 1, 'fp16': False, 'fp16_opt_level': 'O1', 'encode_mode': False, 'task_def_list': [{'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.CeCriterion: 0>', 'dropout_p': 'None', 'enable_san': 'False', 'split_names': \"['train', 'test']\", 'metric_meta': '(<Metric.ACC: 0>, <Metric.NoMeanF1: 12>)', 'task_type': '<TaskType.Classification: 1>', 'data_type': '<DataFormat.PremiseOnly: 1>', 'n_class': '3', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f0959c1cef0>', 'self': '{}', '__class__': \"<class 'experiments.exp_def.TaskDef'>\"}]}\n",
            "04/17/2020 07:01:44 ####################\n",
            "04/17/2020 07:01:44 ############# Gradient Accumulation Info #############\n",
            "04/17/2020 07:01:44 number of step: 6865\n",
            "04/17/2020 07:01:44 number of grad grad_accumulation step: 1\n",
            "04/17/2020 07:01:44 adjusted number of step: 6865\n",
            "04/17/2020 07:01:44 ############# Gradient Accumulation Info #############\n",
            "04/17/2020 07:01:57 \n",
            "############# Model Arch of MT-DNN #############\n",
            "SANBertNetwork(\n",
            "  (dropout_list): ModuleList(\n",
            "    (0): DropoutWrapper()\n",
            "  )\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (scoring_list): ModuleList(\n",
            "    (0): Linear(in_features=768, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "04/17/2020 07:01:57 Total number of params: 109484547\n",
            "04/17/2020 07:01:57 At epoch 0\n",
            "04/17/2020 07:02:06 Task [ 0] updates[     1] train loss[1.15933] remaining[3:21:17]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 359, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 290, in main\n",
            "    model.update(batch_meta, batch_data)\n",
            "  File \"/content/mt-dnn_port/mt-dnn/mt_dnn/model.py\", line 202, in update\n",
            "    self.optimizer.step()\n",
            "  File \"/content/mt-dnn_port/mt-dnn/module/bert_optim.py\", line 126, in step\n",
            "    torch.max(norm_buf, 0, keepdim=False, out=(exp_inf, exp_inf.new().long()))\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuhUcumffS3m",
        "colab_type": "text"
      },
      "source": [
        "Show test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNEzOC_efbGR",
        "colab_type": "code",
        "outputId": "5c61daa0-5db5-43b6-f27c-5f89d86d2f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "\n",
        "filepath = 'checkpoint/{}_test_scores_4.json'.format(TASK) \n",
        "with open(filepath) as f:\n",
        "    scores = json.load(f)\n",
        "\n",
        "print(scores['metrics'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Pearson': 85.01105592648992, 'MSE': 13.714753768382353}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "st-dnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
