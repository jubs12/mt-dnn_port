Preparing train arguments
I0507 02:06:30.872121 139675510707968 file_utils.py:41] PyTorch version 1.1.0a0+be364ac available.
I0507 02:06:31.612277 139675510707968 filelock.py:274] Lock 139675057529856 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock
I0507 02:06:31.613023 139675510707968 file_utils.py:479] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpl_j93gad
Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]Downloading:   0%|          | 1.02k/232k [00:00<00:27, 8.34kB/s]Downloading:  15%|█▌        | 34.8k/232k [00:00<00:16, 11.8kB/s]Downloading:  38%|███▊      | 87.0k/232k [00:00<00:08, 16.6kB/s]Downloading:  75%|███████▌  | 174k/232k [00:00<00:02, 23.5kB/s] Downloading: 100%|██████████| 232k/232k [00:00<00:00, 464kB/s] 
I0507 02:06:32.714504 139675510707968 file_utils.py:489] storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
I0507 02:06:32.714738 139675510707968 file_utils.py:492] creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
I0507 02:06:32.715427 139675510707968 filelock.py:318] Lock 139675057529856 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock
I0507 02:06:32.715563 139675510707968 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
05/07/2020 02:06:32 Task assin-ptbr-sts
05/07/2020 02:06:32 ../data/input/en/bert_base_uncased_lower/assin-ptbr-sts_train.json
05/07/2020 02:06:35 ../data/input/en/bert_base_uncased_lower/assin-ptbr-sts_dev.json
05/07/2020 02:06:36 ../data/input/en/bert_base_uncased_lower/assin-ptbr-sts_test.json
05/07/2020 02:06:38 Task assin-ptbr-rte
05/07/2020 02:06:38 ../data/input/en/bert_base_uncased_lower/assin-ptbr-rte_train.json
05/07/2020 02:06:40 ../data/input/en/bert_base_uncased_lower/assin-ptbr-rte_dev.json
05/07/2020 02:06:41 ../data/input/en/bert_base_uncased_lower/assin-ptbr-rte_test.json
05/07/2020 02:06:43 Task assin-ptpt-sts
05/07/2020 02:06:43 ../data/input/en/bert_base_uncased_lower/assin-ptpt-sts_train.json
05/07/2020 02:06:46 ../data/input/en/bert_base_uncased_lower/assin-ptpt-sts_dev.json
05/07/2020 02:06:47 ../data/input/en/bert_base_uncased_lower/assin-ptpt-sts_test.json
05/07/2020 02:06:49 Task assin2-rte
05/07/2020 02:06:49 ../data/input/en/bert_base_uncased_lower/assin2-rte_train.json
05/07/2020 02:06:54 ../data/input/en/bert_base_uncased_lower/assin2-rte_dev.json
05/07/2020 02:06:54 ../data/input/en/bert_base_uncased_lower/assin2-rte_test.json
05/07/2020 02:06:56 Task assin-ptpt-rte
05/07/2020 02:06:56 ../data/input/en/bert_base_uncased_lower/assin-ptpt-rte_train.json
05/07/2020 02:06:59 ../data/input/en/bert_base_uncased_lower/assin-ptpt-rte_dev.json
05/07/2020 02:06:59 ../data/input/en/bert_base_uncased_lower/assin-ptpt-rte_test.json
05/07/2020 02:07:01 Task assin2-sts
05/07/2020 02:07:02 ../data/input/en/bert_base_uncased_lower/assin2-sts_train.json
05/07/2020 02:07:06 ../data/input/en/bert_base_uncased_lower/assin2-sts_dev.json
05/07/2020 02:07:07 ../data/input/en/bert_base_uncased_lower/assin2-sts_test.json
I0507 02:07:10.253559 140580425697024 file_utils.py:41] PyTorch version 1.1.0a0+be364ac available.
Namespace(adam_eps=1e-06, answer_att_hidden_size=128, answer_att_type='bilinear', answer_dropout_p=0.1, answer_mem_drop_p=0.1, answer_mem_type=1, answer_merge_opt=1, answer_num_turn=5, answer_opt=0, answer_rnn_type='gru', answer_sum_att_type='bilinear', answer_weight_norm_on=False, batch_size=8, batch_size_eval=8, bert_dropout_p=0.1, bert_l2norm=0.0, bert_model_type='bert-base-uncased', cuda=True, data_dir='../data/input/en/bert_base_uncased_lower', data_sort_on=False, do_lower_case=False, dropout_p=0.1, dropout_w=0.0, dump_state_on=False, embedding_opt=0, encode_mode=False, encoder_type=<EncoderModelType.BERT: 1>, epochs=5, fp16=True, fp16_opt_level='O1', freeze_layers=-1, global_grad_clipping=1.0, glue_format_on=False, grad_accumulation_step=1, grad_clipping=0, have_lr_scheduler=True, init_checkpoint='bert-base-uncased', init_ratio=1, learning_rate=5e-05, log_file='mt-dnn-train.log', log_per_updates=500, lr_gamma=0.5, masked_lm_prob=0.15, max_answer_len=5, max_predictions_per_seq=128, max_seq_len=512, mem_cum_type='simple', mix_opt=0, mkd_opt=0, model_ckpt='checkpoints/model_0.pt', momentum=0, mtl_opt=0, multi_gpu_on=False, multi_step_lr='10,20,30', name='farmer', num_hidden_layers=-1, optimizer='adamax', output_dir='../output/mt-dnn_assin/bert_base/seed/2018', ratio=0, resume=False, save_per_updates=10000, save_per_updates_on=False, scheduler_type='ms', seed=2018, short_seq_prob=0.2, task_def='../data/task-def/assin.yaml', tensorboard=True, tensorboard_logdir='tensorboard_logdir', test_datasets=['assin-ptbr-sts', 'assin-ptbr-rte', 'assin-ptpt-sts', 'assin2-rte', 'assin-ptpt-rte', 'assin2-sts'], train_datasets=['assin-ptbr-sts', 'assin-ptbr-rte', 'assin-ptpt-sts', 'assin2-rte', 'assin-ptpt-rte', 'assin2-sts'], update_bert_opt=0, vb_dropout=True, warmup=0.1, warmup_schedule='warmup_linear', weight_decay=0)
05/07/2020 02:07:11 0
05/07/2020 02:07:11 Launching the MT-DNN training
05/07/2020 02:07:11 Loading ../data/input/en/bert_base_uncased_lower/assin-ptbr-sts_train.json as task 0
Loaded 2500 samples out of 2500
05/07/2020 02:07:11 Loading ../data/input/en/bert_base_uncased_lower/assin-ptbr-rte_train.json as task 1
Loaded 2500 samples out of 2500
05/07/2020 02:07:11 Loading ../data/input/en/bert_base_uncased_lower/assin-ptpt-sts_train.json as task 2
Loaded 2500 samples out of 2500
05/07/2020 02:07:11 Loading ../data/input/en/bert_base_uncased_lower/assin2-rte_train.json as task 3
Loaded 6500 samples out of 6500
05/07/2020 02:07:11 Loading ../data/input/en/bert_base_uncased_lower/assin-ptpt-rte_train.json as task 4
Loaded 2500 samples out of 2500
05/07/2020 02:07:11 Loading ../data/input/en/bert_base_uncased_lower/assin2-sts_train.json as task 5
Loaded 6500 samples out of 6500
Loaded 500 samples out of 500
Loaded 2000 samples out of 2000
Loaded 500 samples out of 500
Loaded 2000 samples out of 2000
Loaded 500 samples out of 500
Loaded 2000 samples out of 2000
Loaded 500 samples out of 500
Loaded 2448 samples out of 2448
Loaded 500 samples out of 500
Loaded 2000 samples out of 2000
Loaded 500 samples out of 500
Loaded 2448 samples out of 2448
05/07/2020 02:07:11 ####################
05/07/2020 02:07:11 {'log_file': 'mt-dnn-train.log', 'tensorboard': True, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'bert-base-uncased', 'data_dir': '../data/input/en/bert_base_uncased_lower', 'data_sort_on': False, 'name': 'farmer', 'task_def': '../data/task-def/assin.yaml', 'train_datasets': ['assin-ptbr-sts', 'assin-ptbr-rte', 'assin-ptpt-sts', 'assin2-rte', 'assin-ptpt-rte', 'assin2-sts'], 'test_datasets': ['assin-ptbr-sts', 'assin-ptbr-rte', 'assin-ptpt-sts', 'assin2-rte', 'assin-ptpt-rte', 'assin2-sts'], 'glue_format_on': False, 'mkd_opt': 0, 'update_bert_opt': 0, 'multi_gpu_on': False, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 5, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': 0, 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': <EncoderModelType.BERT: 1>, 'num_hidden_layers': -1, 'bert_model_type': 'bert-base-uncased', 'do_lower_case': False, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'cuda': True, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 5, 'batch_size': 8, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'freeze_layers': -1, 'embedding_opt': 0, 'lr_gamma': 0.5, 'bert_l2norm': 0.0, 'scheduler_type': 'ms', 'output_dir': '../output/mt-dnn_assin/bert_base/seed/2018', 'seed': 2018, 'grad_accumulation_step': 1, 'fp16': True, 'fp16_opt_level': 'O1', 'encode_mode': False, 'task_def_list': [{'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.MseCriterion: 1>', 'dropout_p': 'None', 'enable_san': 'False', 'split_names': "['train', 'dev', 'test']", 'metric_meta': '(<Metric.Pearson: 3>, <Metric.MSE: 11>)', 'task_type': '<TaskType.Regression: 2>', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'n_class': '1', 'label_vocab': 'None', 'self': '{}', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.CeCriterion: 0>', 'dropout_p': 'None', 'enable_san': 'True', 'split_names': "['train', 'dev', 'test']", 'metric_meta': '(<Metric.F1MAC: 9>, <Metric.ACC: 0>)', 'task_type': '<TaskType.Classification: 1>', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'n_class': '3', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7fdb354d1f28>', 'self': '{}', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.MseCriterion: 1>', 'dropout_p': 'None', 'enable_san': 'False', 'split_names': "['train', 'dev', 'test']", 'metric_meta': '(<Metric.Pearson: 3>, <Metric.MSE: 11>)', 'task_type': '<TaskType.Regression: 2>', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'n_class': '1', 'label_vocab': 'None', 'self': '{}', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.CeCriterion: 0>', 'dropout_p': 'None', 'enable_san': 'True', 'split_names': "['train', 'dev', 'test']", 'metric_meta': '(<Metric.F1MAC: 9>, <Metric.ACC: 0>)', 'task_type': '<TaskType.Classification: 1>', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'n_class': '2', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7fdb354d1dd8>', 'self': '{}', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.CeCriterion: 0>', 'dropout_p': 'None', 'enable_san': 'True', 'split_names': "['train', 'dev', 'test']", 'metric_meta': '(<Metric.F1MAC: 9>, <Metric.ACC: 0>)', 'task_type': '<TaskType.Classification: 1>', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'n_class': '3', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7fdb354d1e48>', 'self': '{}', '__class__': "<class 'experiments.exp_def.TaskDef'>"}, {'kd_loss': '<LossCriterion.MseCriterion: 1>', 'loss': '<LossCriterion.MseCriterion: 1>', 'dropout_p': 'None', 'enable_san': 'False', 'split_names': "['train', 'dev', 'test']", 'metric_meta': '(<Metric.Pearson: 3>, <Metric.MSE: 11>)', 'task_type': '<TaskType.Regression: 2>', 'data_type': '<DataFormat.PremiseAndOneHypothesis: 2>', 'n_class': '1', 'label_vocab': 'None', 'self': '{}', '__class__': "<class 'experiments.exp_def.TaskDef'>"}]}
05/07/2020 02:07:11 ####################
05/07/2020 02:07:11 ############# Gradient Accumulation Info #############
05/07/2020 02:07:11 number of step: 14390
05/07/2020 02:07:11 number of grad grad_accumulation step: 1
05/07/2020 02:07:11 adjusted number of step: 14390
05/07/2020 02:07:11 ############# Gradient Accumulation Info #############
I0507 02:07:12.361803 140580425697024 filelock.py:274] Lock 140579469541784 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock
I0507 02:07:12.362517 140580425697024 file_utils.py:479] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpqer4g8bq
Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]Downloading: 100%|██████████| 433/433 [00:00<00:00, 295kB/s]
I0507 02:07:12.980330 140580425697024 file_utils.py:489] storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
I0507 02:07:12.980532 140580425697024 file_utils.py:492] creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
I0507 02:07:12.981258 140580425697024 filelock.py:318] Lock 140579469541784 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock
I0507 02:07:12.981471 140580425697024 configuration_utils.py:283] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
I0507 02:07:12.981978 140580425697024 configuration_utils.py:319] Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": null,
  "decoder_start_token_id": null,
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522
}

I0507 02:07:12.984333 140580425697024 configuration_utils.py:319] Model config BertConfig {
  "_num_labels": 2,
  "adam_eps": 1e-06,
  "answer_att_hidden_size": 128,
  "answer_att_type": "bilinear",
  "answer_dropout_p": 0.1,
  "answer_mem_drop_p": 0.1,
  "answer_mem_type": 1,
  "answer_merge_opt": 1,
  "answer_num_turn": 5,
  "answer_opt": 0,
  "answer_rnn_type": "gru",
  "answer_sum_att_type": "bilinear",
  "answer_weight_norm_on": false,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "batch_size": 8,
  "batch_size_eval": 8,
  "bert_dropout_p": 0.1,
  "bert_l2norm": 0.0,
  "bert_model_type": "bert-base-uncased",
  "bos_token_id": null,
  "cuda": true,
  "data_dir": "../data/input/en/bert_base_uncased_lower",
  "data_sort_on": false,
  "decoder_start_token_id": null,
  "do_lower_case": false,
  "do_sample": false,
  "dropout_p": 0.1,
  "dropout_w": 0.0,
  "dump_state_on": false,
  "early_stopping": false,
  "embedding_opt": 0,
  "encode_mode": false,
  "encoder_type": 1,
  "eos_token_id": null,
  "epochs": 5,
  "finetuning_task": null,
  "fp16": true,
  "fp16_opt_level": "O1",
  "freeze_layers": -1,
  "global_grad_clipping": 1.0,
  "glue_format_on": false,
  "grad_accumulation_step": 1,
  "grad_clipping": 0,
  "have_lr_scheduler": true,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "init_checkpoint": "bert-base-uncased",
  "init_ratio": 1,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "learning_rate": 5e-05,
  "length_penalty": 1.0,
  "log_file": "mt-dnn-train.log",
  "log_per_updates": 500,
  "lr_gamma": 0.5,
  "masked_lm_prob": 0.15,
  "max_answer_len": 5,
  "max_length": 20,
  "max_position_embeddings": 512,
  "max_predictions_per_seq": 128,
  "max_seq_len": 512,
  "mem_cum_type": "simple",
  "min_length": 0,
  "mix_opt": 0,
  "mkd_opt": 0,
  "model_ckpt": "checkpoints/model_0.pt",
  "model_type": "bert",
  "momentum": 0,
  "mtl_opt": 0,
  "multi_gpu_on": false,
  "multi_step_lr": "10,20,30",
  "name": "farmer",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "optimizer": "adamax",
  "output_attentions": false,
  "output_dir": "../output/mt-dnn_assin/bert_base/seed/2018",
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "prefix": null,
  "pruned_heads": {},
  "ratio": 0,
  "repetition_penalty": 1.0,
  "resume": false,
  "save_per_updates": 10000,
  "save_per_updates_on": false,
  "scheduler_type": "ms",
  "seed": 2018,
  "short_seq_prob": 0.2,
  "task_def": "../data/task-def/assin.yaml",
  "task_def_list": [
    {
      "__class__": "<class 'experiments.exp_def.TaskDef'>",
      "data_type": "<DataFormat.PremiseAndOneHypothesis: 2>",
      "dropout_p": "None",
      "enable_san": "False",
      "kd_loss": "<LossCriterion.MseCriterion: 1>",
      "label_vocab": "None",
      "loss": "<LossCriterion.MseCriterion: 1>",
      "metric_meta": "(<Metric.Pearson: 3>, <Metric.MSE: 11>)",
      "n_class": "1",
      "self": "{}",
      "split_names": "['train', 'dev', 'test']",
      "task_type": "<TaskType.Regression: 2>"
    },
    {
      "__class__": "<class 'experiments.exp_def.TaskDef'>",
      "data_type": "<DataFormat.PremiseAndOneHypothesis: 2>",
      "dropout_p": "None",
      "enable_san": "True",
      "kd_loss": "<LossCriterion.MseCriterion: 1>",
      "label_vocab": "<data_utils.vocab.Vocabulary object at 0x7fdb354d1f28>",
      "loss": "<LossCriterion.CeCriterion: 0>",
      "metric_meta": "(<Metric.F1MAC: 9>, <Metric.ACC: 0>)",
      "n_class": "3",
      "self": "{}",
      "split_names": "['train', 'dev', 'test']",
      "task_type": "<TaskType.Classification: 1>"
    },
    {
      "__class__": "<class 'experiments.exp_def.TaskDef'>",
      "data_type": "<DataFormat.PremiseAndOneHypothesis: 2>",
      "dropout_p": "None",
      "enable_san": "False",
      "kd_loss": "<LossCriterion.MseCriterion: 1>",
      "label_vocab": "None",
      "loss": "<LossCriterion.MseCriterion: 1>",
      "metric_meta": "(<Metric.Pearson: 3>, <Metric.MSE: 11>)",
      "n_class": "1",
      "self": "{}",
      "split_names": "['train', 'dev', 'test']",
      "task_type": "<TaskType.Regression: 2>"
    },
    {
      "__class__": "<class 'experiments.exp_def.TaskDef'>",
      "data_type": "<DataFormat.PremiseAndOneHypothesis: 2>",
      "dropout_p": "None",
      "enable_san": "True",
      "kd_loss": "<LossCriterion.MseCriterion: 1>",
      "label_vocab": "<data_utils.vocab.Vocabulary object at 0x7fdb354d1dd8>",
      "loss": "<LossCriterion.CeCriterion: 0>",
      "metric_meta": "(<Metric.F1MAC: 9>, <Metric.ACC: 0>)",
      "n_class": "2",
      "self": "{}",
      "split_names": "['train', 'dev', 'test']",
      "task_type": "<TaskType.Classification: 1>"
    },
    {
      "__class__": "<class 'experiments.exp_def.TaskDef'>",
      "data_type": "<DataFormat.PremiseAndOneHypothesis: 2>",
      "dropout_p": "None",
      "enable_san": "True",
      "kd_loss": "<LossCriterion.MseCriterion: 1>",
      "label_vocab": "<data_utils.vocab.Vocabulary object at 0x7fdb354d1e48>",
      "loss": "<LossCriterion.CeCriterion: 0>",
      "metric_meta": "(<Metric.F1MAC: 9>, <Metric.ACC: 0>)",
      "n_class": "3",
      "self": "{}",
      "split_names": "['train', 'dev', 'test']",
      "task_type": "<TaskType.Classification: 1>"
    },
    {
      "__class__": "<class 'experiments.exp_def.TaskDef'>",
      "data_type": "<DataFormat.PremiseAndOneHypothesis: 2>",
      "dropout_p": "None",
      "enable_san": "False",
      "kd_loss": "<LossCriterion.MseCriterion: 1>",
      "label_vocab": "None",
      "loss": "<LossCriterion.MseCriterion: 1>",
      "metric_meta": "(<Metric.Pearson: 3>, <Metric.MSE: 11>)",
      "n_class": "1",
      "self": "{}",
      "split_names": "['train', 'dev', 'test']",
      "task_type": "<TaskType.Regression: 2>"
    }
  ],
  "task_specific_params": null,
  "temperature": 1.0,
  "tensorboard": true,
  "tensorboard_logdir": "tensorboard_logdir",
  "test_datasets": [
    "assin-ptbr-sts",
    "assin-ptbr-rte",
    "assin-ptpt-sts",
    "assin2-rte",
    "assin-ptpt-rte",
    "assin2-sts"
  ],
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "train_datasets": [
    "assin-ptbr-sts",
    "assin-ptbr-rte",
    "assin-ptpt-sts",
    "assin2-rte",
    "assin-ptpt-rte",
    "assin2-sts"
  ],
  "type_vocab_size": 2,
  "update_bert_opt": 0,
  "use_bfloat16": false,
  "vb_dropout": true,
  "vocab_size": 30522,
  "warmup": 0.1,
  "warmup_schedule": "warmup_linear",
  "weight_decay": 0
}

I0507 02:07:17.053223 140580425697024 filelock.py:274] Lock 140578798421888 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
I0507 02:07:17.054091 140580425697024 file_utils.py:479] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpbl3z003e
Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]Downloading:   0%|          | 9.22k/440M [00:00<1:36:15, 76.3kB/s]Downloading:   0%|          | 44.0k/440M [00:00<1:15:06, 97.7kB/s]Downloading:   0%|          | 96.3k/440M [00:00<57:43, 127kB/s]   Downloading:   0%|          | 218k/440M [00:00<42:36, 172kB/s] Downloading:   0%|          | 462k/440M [00:00<30:54, 237kB/s]Downloading:   0%|          | 967k/440M [00:00<22:08, 331kB/s]Downloading:   0%|          | 1.37M/440M [00:00<16:52, 434kB/s]Downloading:   1%|          | 3.11M/440M [00:01<11:54, 612kB/s]Downloading:   1%|          | 3.69M/440M [00:01<08:58, 811kB/s]Downloading:   1%|          | 4.70M/440M [00:01<06:30, 1.11MB/s]Downloading:   1%|          | 5.39M/440M [00:01<04:56, 1.47MB/s]Downloading:   1%|▏         | 6.10M/440M [00:01<03:50, 1.89MB/s]Downloading:   2%|▏         | 6.80M/440M [00:01<03:03, 2.37MB/s]Downloading:   2%|▏         | 7.50M/440M [00:01<02:30, 2.88MB/s]Downloading:   2%|▏         | 8.23M/440M [00:01<02:07, 3.40MB/s]Downloading:   2%|▏         | 8.96M/440M [00:02<01:50, 3.91MB/s]Downloading:   2%|▏         | 9.70M/440M [00:02<01:38, 4.36MB/s]Downloading:   2%|▏         | 10.4M/440M [00:02<01:30, 4.76MB/s]Downloading:   3%|▎         | 11.2M/440M [00:02<01:24, 5.10MB/s]Downloading:   3%|▎         | 11.9M/440M [00:02<01:19, 5.38MB/s]Downloading:   3%|▎         | 12.7M/440M [00:02<01:16, 5.62MB/s]Downloading:   3%|▎         | 13.5M/440M [00:02<01:13, 5.80MB/s]Downloading:   3%|▎         | 14.2M/440M [00:02<01:11, 5.95MB/s]Downloading:   3%|▎         | 15.0M/440M [00:03<01:10, 6.05MB/s]Downloading:   4%|▎         | 15.8M/440M [00:03<01:08, 6.16MB/s]Downloading:   4%|▍         | 16.6M/440M [00:03<01:07, 6.24MB/s]Downloading:   4%|▍         | 17.4M/440M [00:03<01:07, 6.30MB/s]Downloading:   4%|▍         | 18.2M/440M [00:03<01:06, 6.36MB/s]Downloading:   4%|▍         | 19.0M/440M [00:03<01:05, 6.40MB/s]Downloading:   4%|▍         | 19.8M/440M [00:03<01:05, 6.45MB/s]Downloading:   5%|▍         | 20.6M/440M [00:03<01:04, 6.48MB/s]Downloading:   5%|▍         | 21.4M/440M [00:04<01:04, 6.51MB/s]Downloading:   5%|▌         | 22.2M/440M [00:04<01:03, 6.55MB/s]Downloading:   5%|▌         | 23.0M/440M [00:04<01:03, 6.59MB/s]Downloading:   5%|▌         | 23.8M/440M [00:04<01:03, 6.60MB/s]Downloading:   6%|▌         | 24.6M/440M [00:04<01:02, 6.64MB/s]Downloading:   6%|▌         | 25.4M/440M [00:04<01:02, 6.66MB/s]Downloading:   6%|▌         | 26.3M/440M [00:04<01:01, 6.68MB/s]Downloading:   6%|▌         | 27.1M/440M [00:04<01:01, 6.69MB/s]Downloading:   6%|▋         | 27.9M/440M [00:05<01:01, 6.70MB/s]Downloading:   7%|▋         | 28.8M/440M [00:05<01:01, 6.73MB/s]Downloading:   7%|▋         | 29.6M/440M [00:05<01:01, 6.73MB/s]Downloading:   7%|▋         | 30.4M/440M [00:05<01:00, 6.75MB/s]Downloading:   7%|▋         | 31.2M/440M [00:05<01:00, 6.78MB/s]Downloading:   7%|▋         | 32.1M/440M [00:05<00:56, 7.18MB/s]Downloading:   7%|▋         | 32.8M/440M [00:05<00:59, 6.91MB/s]Downloading:   8%|▊         | 33.5M/440M [00:05<01:00, 6.73MB/s]Downloading:   8%|▊         | 34.3M/440M [00:05<01:00, 6.74MB/s]Downloading:   8%|▊         | 35.1M/440M [00:06<00:59, 6.77MB/s]Downloading:   8%|▊         | 36.0M/440M [00:06<00:57, 7.06MB/s]Downloading:   8%|▊         | 36.8M/440M [00:06<00:57, 6.99MB/s]Downloading:   9%|▊         | 37.7M/440M [00:06<00:57, 6.95MB/s]Downloading:   9%|▊         | 38.5M/440M [00:06<01:00, 6.68MB/s]Downloading:   9%|▉         | 39.3M/440M [00:06<00:59, 6.73MB/s]Downloading:   9%|▉         | 40.2M/440M [00:06<00:56, 7.04MB/s]Downloading:   9%|▉         | 41.0M/440M [00:06<00:57, 6.98MB/s]Downloading:  10%|▉         | 41.8M/440M [00:07<00:57, 6.95MB/s]Downloading:  10%|▉         | 42.7M/440M [00:07<00:59, 6.68MB/s]Downloading:  10%|▉         | 43.5M/440M [00:07<00:59, 6.71MB/s]Downloading:  10%|█         | 44.4M/440M [00:07<00:56, 7.03MB/s]Downloading:  10%|█         | 45.2M/440M [00:07<00:56, 6.98MB/s]Downloading:  10%|█         | 46.0M/440M [00:07<00:56, 6.95MB/s]Downloading:  11%|█         | 46.9M/440M [00:07<00:58, 6.67MB/s]Downloading:  11%|█         | 47.7M/440M [00:07<00:58, 6.72MB/s]Downloading:  11%|█         | 48.6M/440M [00:08<00:55, 7.03MB/s]Downloading:  11%|█         | 49.4M/440M [00:08<00:55, 6.99MB/s]Downloading:  11%|█▏        | 50.2M/440M [00:08<00:56, 6.95MB/s]Downloading:  12%|█▏        | 51.1M/440M [00:08<00:53, 7.31MB/s]Downloading:  12%|█▏        | 51.8M/440M [00:08<00:56, 6.93MB/s]Downloading:  12%|█▏        | 52.5M/440M [00:08<00:58, 6.60MB/s]Downloading:  12%|█▏        | 53.2M/440M [00:08<01:01, 6.35MB/s]Downloading:  12%|█▏        | 53.9M/440M [00:08<00:59, 6.52MB/s]Downloading:  12%|█▏        | 54.7M/440M [00:08<00:58, 6.63MB/s]Downloading:  13%|█▎        | 55.5M/440M [00:09<00:57, 6.73MB/s]Downloading:  13%|█▎        | 56.3M/440M [00:09<00:54, 7.03MB/s]Downloading:  13%|█▎        | 57.0M/440M [00:09<00:56, 6.85MB/s]Downloading:  13%|█▎        | 57.8M/440M [00:09<00:56, 6.81MB/s]Downloading:  13%|█▎        | 58.6M/440M [00:09<00:54, 6.95MB/s]Downloading:  14%|█▎        | 59.5M/440M [00:09<00:53, 7.06MB/s]Downloading:  14%|█▎        | 60.3M/440M [00:09<00:51, 7.32MB/s]Downloading:  14%|█▍        | 61.0M/440M [00:09<00:54, 6.94MB/s]Downloading:  14%|█▍        | 61.7M/440M [00:09<00:57, 6.62MB/s]Downloading:  14%|█▍        | 62.4M/440M [00:10<00:59, 6.36MB/s]Downloading:  14%|█▍        | 63.1M/440M [00:10<00:56, 6.63MB/s]Downloading:  15%|█▍        | 64.0M/440M [00:10<00:55, 6.74MB/s]Downloading:  15%|█▍        | 64.8M/440M [00:10<00:52, 7.15MB/s]Downloading:  15%|█▍        | 65.5M/440M [00:10<00:54, 6.87MB/s]Downloading:  15%|█▌        | 66.3M/440M [00:10<00:54, 6.88MB/s]Downloading:  15%|█▌        | 67.1M/440M [00:10<00:52, 7.15MB/s]Downloading:  15%|█▌        | 67.8M/440M [00:10<00:51, 7.19MB/s]Downloading:  16%|█▌        | 68.5M/440M [00:10<00:54, 6.85MB/s]Downloading:  16%|█▌        | 69.2M/440M [00:11<00:56, 6.57MB/s]Downloading:  16%|█▌        | 70.0M/440M [00:11<00:54, 6.77MB/s]Downloading:  16%|█▌        | 70.8M/440M [00:11<00:53, 6.87MB/s]Downloading:  16%|█▋        | 71.6M/440M [00:11<00:50, 7.25MB/s]Downloading:  16%|█▋        | 72.4M/440M [00:11<00:52, 6.99MB/s]Downloading:  17%|█▋        | 73.1M/440M [00:11<00:52, 7.04MB/s]Downloading:  17%|█▋        | 74.0M/440M [00:11<00:50, 7.30MB/s]Downloading:  17%|█▋        | 74.7M/440M [00:11<00:50, 7.28MB/s]Downloading:  17%|█▋        | 75.5M/440M [00:11<00:52, 6.96MB/s]Downloading:  17%|█▋        | 76.2M/440M [00:12<00:54, 6.69MB/s]Downloading:  17%|█▋        | 76.9M/440M [00:12<00:52, 6.97MB/s]Downloading:  18%|█▊        | 77.8M/440M [00:12<00:50, 7.14MB/s]Downloading:  18%|█▊        | 78.6M/440M [00:12<00:49, 7.30MB/s]Downloading:  18%|█▊        | 79.3M/440M [00:12<00:50, 7.20MB/s]Downloading:  18%|█▊        | 80.2M/440M [00:12<00:47, 7.56MB/s]Downloading:  18%|█▊        | 80.9M/440M [00:12<00:48, 7.48MB/s]Downloading:  19%|█▊        | 81.7M/440M [00:12<00:50, 7.17MB/s]Downloading:  19%|█▊        | 82.4M/440M [00:12<00:51, 6.94MB/s]Downloading:  19%|█▉        | 83.2M/440M [00:13<00:49, 7.21MB/s]Downloading:  19%|█▉        | 84.1M/440M [00:13<00:48, 7.38MB/s]Downloading:  19%|█▉        | 85.0M/440M [00:13<00:46, 7.64MB/s]Downloading:  19%|█▉        | 85.7M/440M [00:13<00:47, 7.47MB/s]Downloading:  20%|█▉        | 86.6M/440M [00:13<00:46, 7.61MB/s]Downloading:  20%|█▉        | 87.6M/440M [00:13<00:44, 7.89MB/s]Downloading:  20%|██        | 88.4M/440M [00:13<00:45, 7.77MB/s]Downloading:  20%|██        | 89.1M/440M [00:13<00:47, 7.37MB/s]Downloading:  20%|██        | 89.9M/440M [00:13<00:48, 7.25MB/s]Downloading:  21%|██        | 90.8M/440M [00:13<00:45, 7.64MB/s]Downloading:  21%|██        | 91.5M/440M [00:14<01:01, 5.67MB/s]Downloading:  21%|██        | 93.1M/440M [00:14<00:49, 6.96MB/s]Downloading:  21%|██▏       | 94.0M/440M [00:14<00:53, 6.49MB/s]Downloading:  22%|██▏       | 94.8M/440M [00:14<00:56, 6.13MB/s]Downloading:  22%|██▏       | 95.6M/440M [00:14<00:56, 6.10MB/s]Downloading:  22%|██▏       | 96.2M/440M [00:14<00:54, 6.30MB/s]Downloading:  22%|██▏       | 96.9M/440M [00:14<00:53, 6.37MB/s]Downloading:  22%|██▏       | 97.6M/440M [00:15<00:54, 6.27MB/s]Downloading:  22%|██▏       | 98.3M/440M [00:15<00:53, 6.35MB/s]Downloading:  22%|██▏       | 99.0M/440M [00:15<00:51, 6.60MB/s]Downloading:  23%|██▎       | 99.7M/440M [00:15<00:52, 6.47MB/s]Downloading:  23%|██▎       | 100M/440M [00:15<00:54, 6.20MB/s] Downloading:  23%|██▎       | 101M/440M [00:15<00:56, 6.04MB/s]Downloading:  23%|██▎       | 102M/440M [00:15<00:54, 6.26MB/s]Downloading:  23%|██▎       | 103M/440M [00:15<00:51, 6.62MB/s]Downloading:  23%|██▎       | 103M/440M [00:15<00:50, 6.71MB/s]Downloading:  24%|██▎       | 104M/440M [00:16<00:49, 6.78MB/s]Downloading:  24%|██▍       | 105M/440M [00:16<00:47, 7.02MB/s]Downloading:  24%|██▍       | 106M/440M [00:16<00:48, 6.94MB/s]Downloading:  24%|██▍       | 106M/440M [00:16<00:49, 6.73MB/s]Downloading:  24%|██▍       | 107M/440M [00:16<00:50, 6.58MB/s]Downloading:  24%|██▍       | 108M/440M [00:16<00:47, 6.94MB/s]Downloading:  25%|██▍       | 108M/440M [00:16<00:46, 7.12MB/s]Downloading:  25%|██▍       | 109M/440M [00:16<00:46, 7.10MB/s]Downloading:  25%|██▍       | 110M/440M [00:16<00:45, 7.27MB/s]Downloading:  25%|██▌       | 111M/440M [00:16<00:44, 7.43MB/s]Downloading:  25%|██▌       | 112M/440M [00:17<00:45, 7.17MB/s]Downloading:  25%|██▌       | 112M/440M [00:17<00:47, 6.91MB/s]Downloading:  26%|██▌       | 113M/440M [00:17<00:46, 7.10MB/s]Downloading:  26%|██▌       | 114M/440M [00:17<00:44, 7.38MB/s]Downloading:  26%|██▌       | 115M/440M [00:17<00:43, 7.50MB/s]Downloading:  26%|██▌       | 116M/440M [00:17<00:42, 7.56MB/s]Downloading:  26%|██▋       | 116M/440M [00:17<00:41, 7.82MB/s]Downloading:  27%|██▋       | 117M/440M [00:17<00:42, 7.53MB/s]Downloading:  27%|██▋       | 118M/440M [00:17<00:44, 7.27MB/s]Downloading:  27%|██▋       | 119M/440M [00:18<00:44, 7.27MB/s]Downloading:  27%|██▋       | 120M/440M [00:18<00:42, 7.60MB/s]Downloading:  27%|██▋       | 120M/440M [00:18<00:41, 7.75MB/s]Downloading:  27%|██▋       | 121M/440M [00:18<00:41, 7.76MB/s]Downloading:  28%|██▊       | 122M/440M [00:18<00:39, 7.97MB/s]Downloading:  28%|██▊       | 123M/440M [00:18<00:41, 7.70MB/s]Downloading:  28%|██▊       | 124M/440M [00:18<00:42, 7.42MB/s]Downloading:  28%|██▊       | 124M/440M [00:18<00:42, 7.52MB/s]Downloading:  28%|██▊       | 125M/440M [00:18<00:40, 7.84MB/s]Downloading:  29%|██▊       | 126M/440M [00:18<00:39, 7.90MB/s]Downloading:  29%|██▉       | 127M/440M [00:19<00:39, 7.94MB/s]Downloading:  29%|██▉       | 128M/440M [00:19<00:38, 8.05MB/s]Downloading:  29%|██▉       | 129M/440M [00:19<00:59, 5.28MB/s]Downloading:  29%|██▉       | 130M/440M [00:19<00:50, 6.21MB/s]Downloading:  30%|██▉       | 131M/440M [00:19<00:50, 6.20MB/s]Downloading:  30%|██▉       | 131M/440M [00:19<00:49, 6.20MB/s]Downloading:  30%|██▉       | 132M/440M [00:19<00:56, 5.47MB/s]Downloading:  30%|███       | 133M/440M [00:20<01:10, 4.34MB/s]Downloading:  30%|███       | 133M/440M [00:20<01:11, 4.30MB/s]Downloading:  30%|███       | 134M/440M [00:20<01:12, 4.20MB/s]Downloading:  30%|███       | 134M/440M [00:20<01:13, 4.16MB/s]Downloading:  31%|███       | 134M/440M [00:20<01:16, 4.02MB/s]Downloading:  31%|███       | 135M/440M [00:20<01:15, 4.06MB/s]Downloading:  31%|███       | 135M/440M [00:20<01:14, 4.10MB/s]Downloading:  31%|███       | 136M/440M [00:21<01:13, 4.15MB/s]Downloading:  31%|███       | 137M/440M [00:21<01:12, 4.18MB/s]Downloading:  31%|███       | 137M/440M [00:21<01:11, 4.26MB/s]Downloading:  31%|███       | 138M/440M [00:21<01:10, 4.30MB/s]Downloading:  31%|███▏      | 138M/440M [00:21<01:10, 4.30MB/s]Downloading:  31%|███▏      | 139M/440M [00:21<01:09, 4.34MB/s]Downloading:  32%|███▏      | 139M/440M [00:21<01:08, 4.40MB/s]Downloading:  32%|███▏      | 140M/440M [00:21<01:08, 4.41MB/s]Downloading:  32%|███▏      | 140M/440M [00:22<01:07, 4.45MB/s]Downloading:  32%|███▏      | 141M/440M [00:22<01:06, 4.48MB/s]Downloading:  32%|███▏      | 141M/440M [00:22<01:06, 4.47MB/s]Downloading:  32%|███▏      | 142M/440M [00:22<01:05, 4.54MB/s]Downloading:  32%|███▏      | 143M/440M [00:22<01:05, 4.54MB/s]Downloading:  32%|███▏      | 143M/440M [00:22<01:05, 4.55MB/s]Downloading:  33%|███▎      | 144M/440M [00:22<01:05, 4.56MB/s]Downloading:  33%|███▎      | 144M/440M [00:22<01:04, 4.59MB/s]Downloading:  33%|███▎      | 145M/440M [00:22<01:04, 4.59MB/s]Downloading:  33%|███▎      | 145M/440M [00:23<01:03, 4.61MB/s]Downloading:  33%|███▎      | 146M/440M [00:23<01:03, 4.63MB/s]Downloading:  33%|███▎      | 147M/440M [00:23<01:03, 4.62MB/s]Downloading:  33%|███▎      | 147M/440M [00:23<01:03, 4.64MB/s]Downloading:  34%|███▎      | 148M/440M [00:23<01:02, 4.66MB/s]Downloading:  34%|███▎      | 148M/440M [00:23<01:02, 4.67MB/s]Downloading:  34%|███▍      | 149M/440M [00:23<01:02, 4.68MB/s]Downloading:  34%|███▍      | 149M/440M [00:23<01:02, 4.68MB/s]Downloading:  34%|███▍      | 150M/440M [00:24<01:02, 4.69MB/s]Downloading:  34%|███▍      | 151M/440M [00:24<01:01, 4.69MB/s]Downloading:  34%|███▍      | 151M/440M [00:24<01:01, 4.72MB/s]Downloading:  34%|███▍      | 152M/440M [00:24<01:01, 4.71MB/s]Downloading:  35%|███▍      | 152M/440M [00:24<01:01, 4.71MB/s]Downloading:  35%|███▍      | 153M/440M [00:24<01:01, 4.70MB/s]Downloading:  35%|███▍      | 153M/440M [00:24<01:01, 4.70MB/s]Downloading:  35%|███▍      | 154M/440M [00:24<01:00, 4.70MB/s]Downloading:  35%|███▌      | 155M/440M [00:25<01:00, 4.71MB/s]Downloading:  35%|███▌      | 155M/440M [00:25<01:00, 4.72MB/s]Downloading:  35%|███▌      | 156M/440M [00:25<01:00, 4.71MB/s]Downloading:  35%|███▌      | 156M/440M [00:25<01:00, 4.72MB/s]Downloading:  36%|███▌      | 157M/440M [00:25<01:00, 4.71MB/s]Downloading:  36%|███▌      | 157M/440M [00:25<01:00, 4.70MB/s]Downloading:  36%|███▌      | 158M/440M [00:25<01:00, 4.70MB/s]Downloading:  36%|███▌      | 159M/440M [00:25<00:59, 4.70MB/s]Downloading:  36%|███▌      | 159M/440M [00:26<00:59, 4.71MB/s]Downloading:  36%|███▋      | 160M/440M [00:26<00:59, 4.71MB/s]Downloading:  36%|███▋      | 160M/440M [00:26<00:59, 4.72MB/s]Downloading:  37%|███▋      | 161M/440M [00:26<00:59, 4.71MB/s]Downloading:  37%|███▋      | 161M/440M [00:26<00:59, 4.71MB/s]Downloading:  37%|███▋      | 162M/440M [00:26<00:59, 4.71MB/s]Downloading:  37%|███▋      | 163M/440M [00:26<00:59, 4.70MB/s]Downloading:  37%|███▋      | 163M/440M [00:26<00:58, 4.72MB/s]Downloading:  37%|███▋      | 164M/440M [00:27<00:58, 4.73MB/s]Downloading:  37%|███▋      | 164M/440M [00:27<00:58, 4.71MB/s]Downloading:  37%|███▋      | 165M/440M [00:27<00:58, 4.72MB/s]Downloading:  38%|███▊      | 166M/440M [00:27<00:58, 4.73MB/s]Downloading:  38%|███▊      | 166M/440M [00:27<00:58, 4.73MB/s]Downloading:  38%|███▊      | 167M/440M [00:27<00:57, 4.75MB/s]Downloading:  38%|███▊      | 167M/440M [00:27<00:55, 4.96MB/s]Downloading:  38%|███▊      | 168M/440M [00:27<00:56, 4.84MB/s]Downloading:  38%|███▊      | 168M/440M [00:27<00:55, 4.87MB/s]Downloading:  38%|███▊      | 169M/440M [00:28<00:55, 4.87MB/s]Downloading:  38%|███▊      | 169M/440M [00:28<00:55, 4.87MB/s]Downloading:  39%|███▊      | 170M/440M [00:28<00:58, 4.66MB/s]Downloading:  39%|███▊      | 170M/440M [00:28<00:58, 4.62MB/s]Downloading:  39%|███▉      | 171M/440M [00:28<00:57, 4.69MB/s]Downloading:  39%|███▉      | 171M/440M [00:28<00:56, 4.73MB/s]Downloading:  39%|███▉      | 172M/440M [00:28<00:56, 4.78MB/s]Downloading:  39%|███▉      | 173M/440M [00:28<00:55, 4.82MB/s]Downloading:  39%|███▉      | 173M/440M [00:28<00:52, 5.05MB/s]Downloading:  39%|███▉      | 174M/440M [00:29<00:54, 4.91MB/s]Downloading:  40%|███▉      | 174M/440M [00:29<00:53, 5.00MB/s]Downloading:  40%|███▉      | 175M/440M [00:29<01:07, 3.91MB/s]Downloading:  40%|███▉      | 175M/440M [00:29<00:57, 4.58MB/s]Downloading:  40%|███▉      | 176M/440M [00:29<00:58, 4.50MB/s]Downloading:  40%|████      | 177M/440M [00:29<00:57, 4.62MB/s]Downloading:  40%|████      | 177M/440M [00:29<00:55, 4.75MB/s]Downloading:  40%|████      | 178M/440M [00:29<00:54, 4.85MB/s]Downloading:  41%|████      | 178M/440M [00:30<00:53, 4.92MB/s]Downloading:  41%|████      | 179M/440M [00:30<00:52, 4.97MB/s]Downloading:  41%|████      | 180M/440M [00:30<00:51, 5.04MB/s]Downloading:  41%|████      | 180M/440M [00:30<00:51, 5.10MB/s]Downloading:  41%|████      | 181M/440M [00:30<00:50, 5.14MB/s]Downloading:  41%|████      | 182M/440M [00:30<00:49, 5.20MB/s]Downloading:  41%|████▏     | 182M/440M [00:30<00:49, 5.25MB/s]Downloading:  42%|████▏     | 183M/440M [00:30<00:48, 5.32MB/s]Downloading:  42%|████▏     | 184M/440M [00:31<00:47, 5.36MB/s]Downloading:  42%|████▏     | 184M/440M [00:31<00:47, 5.41MB/s]Downloading:  42%|████▏     | 185M/440M [00:31<00:46, 5.46MB/s]Downloading:  42%|████▏     | 186M/440M [00:31<00:46, 5.50MB/s]Downloading:  42%|████▏     | 186M/440M [00:31<00:45, 5.56MB/s]Downloading:  42%|████▏     | 187M/440M [00:31<00:45, 5.63MB/s]Downloading:  43%|████▎     | 188M/440M [00:31<00:44, 5.69MB/s]Downloading:  43%|████▎     | 188M/440M [00:31<00:43, 5.74MB/s]Downloading:  43%|████▎     | 189M/440M [00:32<00:43, 5.81MB/s]Downloading:  43%|████▎     | 190M/440M [00:32<00:42, 5.88MB/s]Downloading:  43%|████▎     | 191M/440M [00:32<00:41, 5.96MB/s]Downloading:  43%|████▎     | 191M/440M [00:32<00:41, 6.02MB/s]Downloading:  44%|████▎     | 192M/440M [00:32<00:40, 6.09MB/s]Downloading:  44%|████▍     | 193M/440M [00:32<00:40, 6.16MB/s]Downloading:  44%|████▍     | 194M/440M [00:32<00:39, 6.24MB/s]Downloading:  44%|████▍     | 195M/440M [00:32<00:38, 6.34MB/s]Downloading:  44%|████▍     | 195M/440M [00:32<00:38, 6.40MB/s]Downloading:  45%|████▍     | 196M/440M [00:33<00:37, 6.51MB/s]Downloading:  45%|████▍     | 197M/440M [00:33<00:37, 6.58MB/s]Downloading:  45%|████▍     | 198M/440M [00:33<00:36, 6.68MB/s]Downloading:  45%|████▌     | 199M/440M [00:33<00:35, 6.80MB/s]Downloading:  45%|████▌     | 200M/440M [00:33<00:34, 6.89MB/s]Downloading:  46%|████▌     | 201M/440M [00:33<00:34, 7.00MB/s]Downloading:  46%|████▌     | 201M/440M [00:33<00:33, 7.10MB/s]Downloading:  46%|████▌     | 202M/440M [00:33<00:33, 7.22MB/s]Downloading:  46%|████▌     | 203M/440M [00:34<00:32, 7.34MB/s]Downloading:  46%|████▋     | 204M/440M [00:34<00:31, 7.44MB/s]Downloading:  47%|████▋     | 205M/440M [00:34<00:31, 7.51MB/s]Downloading:  47%|████▋     | 206M/440M [00:34<00:30, 7.73MB/s]Downloading:  47%|████▋     | 207M/440M [00:34<00:29, 7.84MB/s]Downloading:  47%|████▋     | 208M/440M [00:34<00:29, 7.97MB/s]Downloading:  47%|████▋     | 209M/440M [00:34<00:28, 8.10MB/s]Downloading:  48%|████▊     | 210M/440M [00:34<00:27, 8.26MB/s]Downloading:  48%|████▊     | 211M/440M [00:35<00:27, 8.39MB/s]Downloading:  48%|████▊     | 212M/440M [00:35<00:26, 8.56MB/s]Downloading:  48%|████▊     | 214M/440M [00:35<00:26, 8.68MB/s]Downloading:  49%|████▊     | 215M/440M [00:35<00:25, 8.83MB/s]Downloading:  49%|████▉     | 216M/440M [00:35<00:24, 9.00MB/s]Downloading:  49%|████▉     | 217M/440M [00:35<00:24, 9.18MB/s]Downloading:  50%|████▉     | 218M/440M [00:35<00:23, 9.34MB/s]Downloading:  50%|████▉     | 219M/440M [00:35<00:23, 9.52MB/s]Downloading:  50%|█████     | 221M/440M [00:36<00:22, 9.63MB/s]Downloading:  50%|█████     | 222M/440M [00:36<00:22, 9.83MB/s]Downloading:  51%|█████     | 223M/440M [00:36<00:21, 10.1MB/s]Downloading:  51%|█████     | 224M/440M [00:36<00:21, 10.3MB/s]Downloading:  51%|█████▏    | 226M/440M [00:36<00:20, 10.4MB/s]Downloading:  52%|█████▏    | 227M/440M [00:36<00:20, 10.6MB/s]Downloading:  52%|█████▏    | 229M/440M [00:36<00:19, 10.9MB/s]Downloading:  52%|█████▏    | 230M/440M [00:36<00:19, 11.0MB/s]Downloading:  53%|█████▎    | 231M/440M [00:37<00:18, 11.2MB/s]Downloading:  53%|█████▎    | 233M/440M [00:37<00:17, 11.5MB/s]Downloading:  53%|█████▎    | 234M/440M [00:37<00:16, 12.3MB/s]Downloading:  53%|█████▎    | 236M/440M [00:37<00:16, 12.3MB/s]Downloading:  54%|█████▍    | 237M/440M [00:37<00:16, 12.0MB/s]Downloading:  54%|█████▍    | 238M/440M [00:37<00:16, 12.1MB/s]Downloading:  54%|█████▍    | 239M/440M [00:37<00:16, 12.0MB/s]Downloading:  55%|█████▍    | 241M/440M [00:37<00:16, 12.4MB/s]Downloading:  55%|█████▌    | 242M/440M [00:37<00:15, 13.0MB/s]Downloading:  55%|█████▌    | 244M/440M [00:37<00:14, 13.7MB/s]Downloading:  56%|█████▌    | 245M/440M [00:38<00:14, 13.6MB/s]Downloading:  56%|█████▌    | 247M/440M [00:38<00:14, 13.5MB/s]Downloading:  56%|█████▋    | 248M/440M [00:38<00:14, 13.7MB/s]Downloading:  57%|█████▋    | 249M/440M [00:38<00:14, 13.6MB/s]Downloading:  57%|█████▋    | 251M/440M [00:38<00:13, 14.1MB/s]Downloading:  57%|█████▋    | 253M/440M [00:38<00:12, 15.1MB/s]Downloading:  58%|█████▊    | 254M/440M [00:38<00:12, 14.8MB/s]Downloading:  58%|█████▊    | 256M/440M [00:38<00:12, 14.8MB/s]Downloading:  58%|█████▊    | 257M/440M [00:38<00:12, 15.1MB/s]Downloading:  59%|█████▉    | 259M/440M [00:39<00:12, 15.0MB/s]Downloading:  59%|█████▉    | 261M/440M [00:39<00:11, 15.6MB/s]Downloading:  60%|█████▉    | 263M/440M [00:39<00:10, 16.5MB/s]Downloading:  60%|██████    | 264M/440M [00:39<00:10, 16.2MB/s]Downloading:  60%|██████    | 266M/440M [00:39<00:10, 16.3MB/s]Downloading:  61%|██████    | 268M/440M [00:39<00:10, 16.3MB/s]Downloading:  61%|██████    | 269M/440M [00:39<00:10, 16.5MB/s]Downloading:  62%|██████▏   | 271M/440M [00:39<00:09, 17.4MB/s]Downloading:  62%|██████▏   | 273M/440M [00:39<00:09, 18.2MB/s]Downloading:  62%|██████▏   | 275M/440M [00:39<00:09, 17.8MB/s]Downloading:  63%|██████▎   | 277M/440M [00:40<00:09, 18.0MB/s]Downloading:  63%|██████▎   | 279M/440M [00:40<00:08, 18.0MB/s]Downloading:  64%|██████▎   | 281M/440M [00:40<00:08, 18.3MB/s]Downloading:  64%|██████▍   | 283M/440M [00:40<00:08, 19.3MB/s]Downloading:  65%|██████▍   | 285M/440M [00:40<00:07, 20.0MB/s]Downloading:  65%|██████▌   | 287M/440M [00:40<00:07, 19.6MB/s]Downloading:  66%|██████▌   | 289M/440M [00:40<00:07, 19.9MB/s]Downloading:  66%|██████▌   | 291M/440M [00:40<00:07, 19.6MB/s]Downloading:  67%|██████▋   | 293M/440M [00:40<00:07, 20.2MB/s]Downloading:  67%|██████▋   | 296M/440M [00:40<00:06, 21.2MB/s]Downloading:  68%|██████▊   | 298M/440M [00:41<00:06, 21.8MB/s]Downloading:  68%|██████▊   | 300M/440M [00:41<00:06, 21.8MB/s]Downloading:  69%|██████▊   | 303M/440M [00:41<00:06, 21.7MB/s]Downloading:  69%|██████▉   | 305M/440M [00:41<00:10, 13.2MB/s]Downloading:  70%|███████   | 308M/440M [00:41<00:08, 14.7MB/s]Downloading:  70%|███████   | 310M/440M [00:41<00:09, 13.1MB/s]Downloading:  71%|███████   | 312M/440M [00:42<00:09, 13.4MB/s]Downloading:  71%|███████   | 313M/440M [00:42<00:09, 13.4MB/s]Downloading:  71%|███████▏  | 315M/440M [00:42<00:09, 12.9MB/s]Downloading:  72%|███████▏  | 316M/440M [00:42<00:09, 12.5MB/s]Downloading:  72%|███████▏  | 318M/440M [00:42<00:13, 9.33MB/s]Downloading:  73%|███████▎  | 320M/440M [00:42<00:11, 11.0MB/s]Downloading:  73%|███████▎  | 321M/440M [00:42<00:11, 10.6MB/s]Downloading:  73%|███████▎  | 322M/440M [00:42<00:11, 10.3MB/s]Downloading:  73%|███████▎  | 323M/440M [00:43<00:12, 9.61MB/s]Downloading:  74%|███████▎  | 324M/440M [00:43<00:12, 9.41MB/s]Downloading:  74%|███████▍  | 325M/440M [00:43<00:12, 9.29MB/s]Downloading:  74%|███████▍  | 326M/440M [00:43<00:12, 8.93MB/s]Downloading:  74%|███████▍  | 327M/440M [00:43<00:13, 8.71MB/s]Downloading:  75%|███████▍  | 328M/440M [00:43<00:12, 8.80MB/s]Downloading:  75%|███████▍  | 329M/440M [00:43<00:12, 8.95MB/s]Downloading:  75%|███████▌  | 331M/440M [00:43<00:12, 9.05MB/s]Downloading:  75%|███████▌  | 332M/440M [00:44<00:11, 9.14MB/s]Downloading:  76%|███████▌  | 333M/440M [00:44<00:11, 9.23MB/s]Downloading:  76%|███████▌  | 334M/440M [00:44<00:11, 9.32MB/s]Downloading:  76%|███████▌  | 335M/440M [00:44<00:11, 9.40MB/s]Downloading:  76%|███████▋  | 336M/440M [00:44<00:10, 9.47MB/s]Downloading:  77%|███████▋  | 338M/440M [00:44<00:10, 9.52MB/s]Downloading:  77%|███████▋  | 338M/440M [00:44<00:13, 7.31MB/s]Downloading:  77%|███████▋  | 340M/440M [00:44<00:11, 8.78MB/s]Downloading:  77%|███████▋  | 341M/440M [00:45<00:10, 9.24MB/s]Downloading:  78%|███████▊  | 342M/440M [00:45<00:10, 9.12MB/s]Downloading:  78%|███████▊  | 343M/440M [00:45<00:10, 9.01MB/s]Downloading:  78%|███████▊  | 344M/440M [00:45<00:10, 8.90MB/s]Downloading:  78%|███████▊  | 346M/440M [00:45<00:10, 9.11MB/s]Downloading:  79%|███████▊  | 347M/440M [00:45<00:10, 9.36MB/s]Downloading:  79%|███████▉  | 348M/440M [00:45<00:09, 9.54MB/s]Downloading:  79%|███████▉  | 349M/440M [00:45<00:09, 9.72MB/s]Downloading:  80%|███████▉  | 350M/440M [00:46<00:09, 9.83MB/s]Downloading:  80%|███████▉  | 352M/440M [00:46<00:08, 9.91MB/s]Downloading:  80%|████████  | 353M/440M [00:46<00:08, 9.98MB/s]Downloading:  80%|████████  | 354M/440M [00:46<00:08, 10.0MB/s]Downloading:  81%|████████  | 355M/440M [00:46<00:12, 6.95MB/s]Downloading:  81%|████████  | 356M/440M [00:46<00:12, 6.59MB/s]Downloading:  81%|████████  | 357M/440M [00:46<00:13, 6.39MB/s]Downloading:  81%|████████  | 357M/440M [00:47<00:14, 5.84MB/s]Downloading:  81%|████████▏ | 358M/440M [00:47<00:14, 5.66MB/s]Downloading:  81%|████████▏ | 359M/440M [00:47<00:14, 5.52MB/s]Downloading:  82%|████████▏ | 359M/440M [00:47<00:14, 5.51MB/s]Downloading:  82%|████████▏ | 360M/440M [00:47<00:15, 5.26MB/s]Downloading:  82%|████████▏ | 360M/440M [00:47<00:15, 5.07MB/s]Downloading:  82%|████████▏ | 361M/440M [00:47<00:15, 5.06MB/s]Downloading:  82%|████████▏ | 362M/440M [00:47<00:15, 5.16MB/s]Downloading:  82%|████████▏ | 362M/440M [00:48<00:14, 5.28MB/s]Downloading:  82%|████████▏ | 363M/440M [00:48<00:14, 5.35MB/s]Downloading:  83%|████████▎ | 364M/440M [00:48<00:14, 5.43MB/s]Downloading:  83%|████████▎ | 364M/440M [00:48<00:13, 5.49MB/s]Downloading:  83%|████████▎ | 365M/440M [00:48<00:13, 5.56MB/s]Downloading:  83%|████████▎ | 366M/440M [00:48<00:13, 5.60MB/s]Downloading:  83%|████████▎ | 366M/440M [00:48<00:13, 5.65MB/s]Downloading:  83%|████████▎ | 367M/440M [00:48<00:12, 5.68MB/s]Downloading:  84%|████████▎ | 368M/440M [00:48<00:12, 5.79MB/s]Downloading:  84%|████████▎ | 369M/440M [00:49<00:12, 5.73MB/s]Downloading:  84%|████████▍ | 369M/440M [00:49<00:12, 5.84MB/s]Downloading:  84%|████████▍ | 370M/440M [00:49<00:12, 5.85MB/s]Downloading:  84%|████████▍ | 371M/440M [00:49<00:11, 5.86MB/s]Downloading:  84%|████████▍ | 371M/440M [00:49<00:11, 5.87MB/s]Downloading:  84%|████████▍ | 372M/440M [00:49<00:14, 4.66MB/s]Downloading:  85%|████████▍ | 373M/440M [00:49<00:12, 5.36MB/s]Downloading:  85%|████████▍ | 374M/440M [00:50<00:12, 5.51MB/s]Downloading:  85%|████████▍ | 374M/440M [00:50<00:11, 5.65MB/s]Downloading:  85%|████████▌ | 375M/440M [00:50<00:11, 5.73MB/s]Downloading:  85%|████████▌ | 376M/440M [00:50<00:11, 5.82MB/s]Downloading:  85%|████████▌ | 377M/440M [00:50<00:10, 5.87MB/s]Downloading:  86%|████████▌ | 377M/440M [00:50<00:10, 5.92MB/s]Downloading:  86%|████████▌ | 378M/440M [00:50<00:10, 5.93MB/s]Downloading:  86%|████████▌ | 379M/440M [00:50<00:10, 5.96MB/s]Downloading:  86%|████████▌ | 379M/440M [00:50<00:10, 5.98MB/s]Downloading:  86%|████████▋ | 380M/440M [00:51<00:10, 6.00MB/s]Downloading:  86%|████████▋ | 381M/440M [00:51<00:09, 6.01MB/s]Downloading:  87%|████████▋ | 382M/440M [00:51<00:09, 6.00MB/s]Downloading:  87%|████████▋ | 382M/440M [00:51<00:09, 6.00MB/s]Downloading:  87%|████████▋ | 383M/440M [00:51<00:09, 6.00MB/s]Downloading:  87%|████████▋ | 384M/440M [00:51<00:09, 6.00MB/s]Downloading:  87%|████████▋ | 385M/440M [00:51<00:09, 6.03MB/s]Downloading:  87%|████████▋ | 385M/440M [00:51<00:09, 6.03MB/s]Downloading:  88%|████████▊ | 386M/440M [00:52<00:09, 6.04MB/s]Downloading:  88%|████████▊ | 387M/440M [00:52<00:08, 6.03MB/s]Downloading:  88%|████████▊ | 388M/440M [00:52<00:08, 6.27MB/s]Downloading:  88%|████████▊ | 388M/440M [00:52<00:08, 5.98MB/s]Downloading:  88%|████████▊ | 389M/440M [00:52<00:08, 6.00MB/s]Downloading:  88%|████████▊ | 390M/440M [00:52<00:08, 6.01MB/s]Downloading:  89%|████████▊ | 391M/440M [00:52<00:08, 6.01MB/s]Downloading:  89%|████████▉ | 391M/440M [00:52<00:08, 6.00MB/s]Downloading:  89%|████████▉ | 392M/440M [00:53<00:08, 6.04MB/s]Downloading:  89%|████████▉ | 393M/440M [00:53<00:07, 6.04MB/s]Downloading:  89%|████████▉ | 394M/440M [00:53<00:07, 6.04MB/s]Downloading:  90%|████████▉ | 394M/440M [00:53<00:07, 6.04MB/s]Downloading:  90%|████████▉ | 395M/440M [00:53<00:07, 6.04MB/s]Downloading:  90%|████████▉ | 396M/440M [00:53<00:07, 6.02MB/s]Downloading:  90%|█████████ | 396M/440M [00:53<00:07, 6.07MB/s]Downloading:  90%|█████████ | 397M/440M [00:53<00:07, 6.06MB/s]Downloading:  90%|█████████ | 398M/440M [00:54<00:07, 6.05MB/s]Downloading:  91%|█████████ | 399M/440M [00:54<00:06, 6.06MB/s]Downloading:  91%|█████████ | 399M/440M [00:54<00:06, 6.03MB/s]Downloading:  91%|█████████ | 400M/440M [00:54<00:06, 6.06MB/s]Downloading:  91%|█████████ | 401M/440M [00:54<00:06, 6.08MB/s]Downloading:  91%|█████████ | 402M/440M [00:54<00:06, 6.05MB/s]Downloading:  91%|█████████▏| 402M/440M [00:54<00:06, 6.09MB/s]Downloading:  92%|█████████▏| 403M/440M [00:54<00:06, 6.07MB/s]Downloading:  92%|█████████▏| 404M/440M [00:55<00:05, 6.11MB/s]Downloading:  92%|█████████▏| 405M/440M [00:55<00:05, 6.11MB/s]Downloading:  92%|█████████▏| 405M/440M [00:55<00:05, 6.10MB/s]Downloading:  92%|█████████▏| 406M/440M [00:55<00:05, 6.13MB/s]Downloading:  92%|█████████▏| 407M/440M [00:55<00:05, 6.14MB/s]Downloading:  93%|█████████▎| 408M/440M [00:55<00:05, 6.15MB/s]Downloading:  93%|█████████▎| 408M/440M [00:55<00:05, 6.15MB/s]Downloading:  93%|█████████▎| 409M/440M [00:55<00:05, 6.15MB/s]Downloading:  93%|█████████▎| 410M/440M [00:56<00:04, 6.17MB/s]Downloading:  93%|█████████▎| 411M/440M [00:56<00:04, 6.19MB/s]Downloading:  93%|█████████▎| 411M/440M [00:56<00:04, 6.21MB/s]Downloading:  94%|█████████▎| 412M/440M [00:56<00:04, 6.22MB/s]Downloading:  94%|█████████▍| 413M/440M [00:56<00:04, 6.24MB/s]Downloading:  94%|█████████▍| 414M/440M [00:56<00:04, 6.26MB/s]Downloading:  94%|█████████▍| 415M/440M [00:56<00:04, 6.30MB/s]Downloading:  94%|█████████▍| 415M/440M [00:56<00:03, 6.30MB/s]Downloading:  94%|█████████▍| 416M/440M [00:56<00:03, 6.32MB/s]Downloading:  95%|█████████▍| 417M/440M [00:57<00:03, 6.35MB/s]Downloading:  95%|█████████▍| 418M/440M [00:57<00:03, 6.37MB/s]Downloading:  95%|█████████▍| 418M/440M [00:57<00:03, 6.40MB/s]Downloading:  95%|█████████▌| 419M/440M [00:57<00:03, 6.44MB/s]Downloading:  95%|█████████▌| 420M/440M [00:57<00:03, 6.48MB/s]Downloading:  96%|█████████▌| 421M/440M [00:57<00:03, 6.50MB/s]Downloading:  96%|█████████▌| 422M/440M [00:57<00:02, 6.53MB/s]Downloading:  96%|█████████▌| 422M/440M [00:57<00:02, 6.58MB/s]Downloading:  96%|█████████▌| 423M/440M [00:58<00:02, 6.63MB/s]Downloading:  96%|█████████▋| 424M/440M [00:58<00:02, 6.68MB/s]Downloading:  96%|█████████▋| 425M/440M [00:58<00:02, 6.72MB/s]Downloading:  97%|█████████▋| 426M/440M [00:58<00:02, 6.78MB/s]Downloading:  97%|█████████▋| 427M/440M [00:58<00:02, 6.82MB/s]Downloading:  97%|█████████▋| 428M/440M [00:58<00:01, 6.88MB/s]Downloading:  97%|█████████▋| 428M/440M [00:58<00:01, 6.92MB/s]Downloading:  97%|█████████▋| 429M/440M [00:58<00:01, 5.98MB/s]Downloading:  98%|█████████▊| 430M/440M [00:59<00:01, 6.54MB/s]Downloading:  98%|█████████▊| 431M/440M [00:59<00:01, 6.07MB/s]Downloading:  98%|█████████▊| 431M/440M [00:59<00:01, 5.78MB/s]Downloading:  98%|█████████▊| 432M/440M [00:59<00:01, 5.54MB/s]Downloading:  98%|█████████▊| 432M/440M [00:59<00:01, 5.51MB/s]Downloading:  98%|█████████▊| 433M/440M [00:59<00:01, 5.47MB/s]Downloading:  98%|█████████▊| 434M/440M [00:59<00:01, 4.41MB/s]Downloading:  99%|█████████▊| 435M/440M [00:59<00:01, 5.17MB/s]Downloading:  99%|█████████▉| 435M/440M [01:00<00:00, 5.33MB/s]Downloading:  99%|█████████▉| 436M/440M [01:00<00:00, 5.48MB/s]Downloading:  99%|█████████▉| 437M/440M [01:00<00:00, 5.60MB/s]Downloading:  99%|█████████▉| 438M/440M [01:00<00:00, 5.70MB/s]Downloading: 100%|█████████▉| 438M/440M [01:00<00:00, 6.08MB/s]Downloading: 100%|█████████▉| 439M/440M [01:00<00:00, 5.80MB/s]Downloading: 100%|█████████▉| 440M/440M [01:00<00:00, 5.65MB/s]Downloading: 100%|█████████▉| 440M/440M [01:00<00:00, 5.80MB/s]Downloading: 100%|██████████| 440M/440M [01:00<00:00, 7.23MB/s]
I0507 02:08:18.608682 140580425697024 file_utils.py:489] storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
I0507 02:08:18.609465 140580425697024 file_utils.py:492] creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
I0507 02:08:18.610342 140580425697024 filelock.py:318] Lock 140578798421888 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
I0507 02:08:18.610581 140580425697024 modeling_utils.py:507] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
05/07/2020 02:08:25 
############# Model Arch of MT-DNN #############
SANBertNetwork(
  (dropout_list): ModuleList(
    (0): DropoutWrapper()
    (1): DropoutWrapper()
    (2): DropoutWrapper()
    (3): DropoutWrapper()
    (4): DropoutWrapper()
    (5): DropoutWrapper()
  )
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (scoring_list): ModuleList(
    (0): Linear(in_features=768, out_features=1, bias=True)
    (1): Linear(in_features=768, out_features=3, bias=True)
    (2): Linear(in_features=768, out_features=1, bias=True)
    (3): Linear(in_features=768, out_features=2, bias=True)
    (4): Linear(in_features=768, out_features=3, bias=True)
    (5): Linear(in_features=768, out_features=1, bias=True)
  )
)

05/07/2020 02:08:25 Total number of params: 109490699
05/07/2020 02:08:25 At epoch 0
05/07/2020 02:08:26 Task [ 3] updates[     1] train loss[0.51471] remaining[0:35:23]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
05/07/2020 02:10:54 Task [ 3] updates[   500] train loss[4.05162] remaining[0:11:46]
05/07/2020 02:13:20 Task [ 1] updates[  1000] train loss[2.48277] remaining[0:09:14]
05/07/2020 02:15:46 Task [ 3] updates[  1500] train loss[1.85250] remaining[0:06:44]
05/07/2020 02:18:13 Task [ 0] updates[  2000] train loss[1.50013] remaining[0:04:17]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
05/07/2020 02:20:42 Task [ 5] updates[  2500] train loss[1.27822] remaining[0:01:51]
predicting 0
05/07/2020 02:22:35 Task assin-ptbr-sts -- epoch 0 -- Dev Pearson: 71.500
05/07/2020 02:22:35 Task assin-ptbr-sts -- epoch 0 -- Dev MSE: 10.038
predicting 0
predicting 100
predicting 200
05/07/2020 02:22:46 [new test scores saved.]
predicting 0
05/07/2020 02:22:49 Task assin-ptbr-rte -- epoch 0 -- Dev F1MAC: 53.168
05/07/2020 02:22:49 Task assin-ptbr-rte -- epoch 0 -- Dev ACC: 84.800
predicting 0
predicting 100
predicting 200
05/07/2020 02:23:00 [new test scores saved.]
predicting 0
05/07/2020 02:23:03 Task assin-ptpt-sts -- epoch 0 -- Dev Pearson: 81.286
05/07/2020 02:23:03 Task assin-ptpt-sts -- epoch 0 -- Dev MSE: 10.606
predicting 0
predicting 100
predicting 200
05/07/2020 02:23:14 [new test scores saved.]
predicting 0
05/07/2020 02:23:16 Task assin2-rte -- epoch 0 -- Dev F1MAC: 90.193
05/07/2020 02:23:16 Task assin2-rte -- epoch 0 -- Dev ACC: 90.200
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 02:23:29 [new test scores saved.]
predicting 0
05/07/2020 02:23:32 Task assin-ptpt-rte -- epoch 0 -- Dev F1MAC: 54.698
05/07/2020 02:23:32 Task assin-ptpt-rte -- epoch 0 -- Dev ACC: 83.000
predicting 0
predicting 100
predicting 200
05/07/2020 02:23:43 [new test scores saved.]
predicting 0
05/07/2020 02:23:46 Task assin2-sts -- epoch 0 -- Dev Pearson: 85.612
05/07/2020 02:23:46 Task assin2-sts -- epoch 0 -- Dev MSE: 16.447
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 02:23:59 [new test scores saved.]
/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
I0507 02:24:01.924709 140580425697024 model.py:278] model saved to /container/mt-dnn_port/output/mt-dnn_assin/bert_base/seed/2018/model_0.pt
05/07/2020 02:24:01 At epoch 1
05/07/2020 02:24:37 Task [ 3] updates[  3000] train loss[1.13069] remaining[0:13:13]
05/07/2020 02:27:02 Task [ 0] updates[  3500] train loss[1.01942] remaining[0:10:55]
05/07/2020 02:29:30 Task [ 5] updates[  4000] train loss[0.93589] remaining[0:08:34]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
05/07/2020 02:31:57 Task [ 3] updates[  4500] train loss[0.86297] remaining[0:06:08]
05/07/2020 02:34:19 Task [ 2] updates[  5000] train loss[0.80491] remaining[0:03:40]
05/07/2020 02:36:47 Task [ 5] updates[  5500] train loss[0.75549] remaining[0:01:14]
predicting 0
05/07/2020 02:38:04 Task assin-ptbr-sts -- epoch 1 -- Dev Pearson: 78.220
05/07/2020 02:38:04 Task assin-ptbr-sts -- epoch 1 -- Dev MSE: 10.038
predicting 0
predicting 100
predicting 200
05/07/2020 02:38:15 [new test scores saved.]
predicting 0
05/07/2020 02:38:17 Task assin-ptbr-rte -- epoch 1 -- Dev F1MAC: 54.714
05/07/2020 02:38:17 Task assin-ptbr-rte -- epoch 1 -- Dev ACC: 87.800
predicting 0
predicting 100
predicting 200
05/07/2020 02:38:28 [new test scores saved.]
predicting 0
05/07/2020 02:38:31 Task assin-ptpt-sts -- epoch 1 -- Dev Pearson: 84.514
05/07/2020 02:38:31 Task assin-ptpt-sts -- epoch 1 -- Dev MSE: 10.606
predicting 0
predicting 100
predicting 200
05/07/2020 02:38:42 [new test scores saved.]
predicting 0
05/07/2020 02:38:45 Task assin2-rte -- epoch 1 -- Dev F1MAC: 94.399
05/07/2020 02:38:45 Task assin2-rte -- epoch 1 -- Dev ACC: 94.400
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 02:38:58 [new test scores saved.]
predicting 0
05/07/2020 02:39:01 Task assin-ptpt-rte -- epoch 1 -- Dev F1MAC: 62.055
05/07/2020 02:39:01 Task assin-ptpt-rte -- epoch 1 -- Dev ACC: 86.200
predicting 0
predicting 100
predicting 200
05/07/2020 02:39:12 [new test scores saved.]
predicting 0
05/07/2020 02:39:15 Task assin2-sts -- epoch 1 -- Dev Pearson: 89.066
05/07/2020 02:39:15 Task assin2-sts -- epoch 1 -- Dev MSE: 16.447
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 02:39:28 [new test scores saved.]
/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
I0507 02:39:31.457293 140580425697024 model.py:278] model saved to /container/mt-dnn_port/output/mt-dnn_assin/bert_base/seed/2018/model_1.pt
05/07/2020 02:39:31 At epoch 2
05/07/2020 02:40:41 Task [ 0] updates[  6000] train loss[0.71416] remaining[0:12:35]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
05/07/2020 02:43:06 Task [ 5] updates[  6500] train loss[0.67823] remaining[0:10:15]
05/07/2020 02:45:33 Task [ 5] updates[  7000] train loss[0.64631] remaining[0:07:55]
05/07/2020 02:48:02 Task [ 3] updates[  7500] train loss[0.61503] remaining[0:05:32]
05/07/2020 02:50:21 Task [ 4] updates[  8000] train loss[0.58777] remaining[0:03:03]
05/07/2020 02:52:44 Task [ 5] updates[  8500] train loss[0.56388] remaining[0:00:38]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
predicting 0
05/07/2020 02:53:24 Task assin-ptbr-sts -- epoch 2 -- Dev Pearson: 77.323
05/07/2020 02:53:24 Task assin-ptbr-sts -- epoch 2 -- Dev MSE: 10.038
predicting 0
predicting 100
predicting 200
05/07/2020 02:53:35 [new test scores saved.]
predicting 0
05/07/2020 02:53:38 Task assin-ptbr-rte -- epoch 2 -- Dev F1MAC: 73.275
05/07/2020 02:53:38 Task assin-ptbr-rte -- epoch 2 -- Dev ACC: 89.000
predicting 0
predicting 100
predicting 200
05/07/2020 02:53:49 [new test scores saved.]
predicting 0
05/07/2020 02:53:52 Task assin-ptpt-sts -- epoch 2 -- Dev Pearson: 85.594
05/07/2020 02:53:52 Task assin-ptpt-sts -- epoch 2 -- Dev MSE: 10.606
predicting 0
predicting 100
predicting 200
05/07/2020 02:54:03 [new test scores saved.]
predicting 0
05/07/2020 02:54:06 Task assin2-rte -- epoch 2 -- Dev F1MAC: 94.798
05/07/2020 02:54:06 Task assin2-rte -- epoch 2 -- Dev ACC: 94.800
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 02:54:20 [new test scores saved.]
predicting 0
05/07/2020 02:54:22 Task assin-ptpt-rte -- epoch 2 -- Dev F1MAC: 78.967
05/07/2020 02:54:22 Task assin-ptpt-rte -- epoch 2 -- Dev ACC: 89.200
predicting 0
predicting 100
predicting 200
05/07/2020 02:54:34 [new test scores saved.]
predicting 0
05/07/2020 02:54:36 Task assin2-sts -- epoch 2 -- Dev Pearson: 90.563
05/07/2020 02:54:36 Task assin2-sts -- epoch 2 -- Dev MSE: 16.447
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 02:54:50 [new test scores saved.]
I0507 02:54:52.843009 140580425697024 model.py:278] model saved to /container/mt-dnn_port/output/mt-dnn_assin/bert_base/seed/2018/model_2.pt
05/07/2020 02:54:52 At epoch 3
05/07/2020 02:56:36 Task [ 3] updates[  9000] train loss[0.54260] remaining[0:11:53]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
05/07/2020 02:58:59 Task [ 4] updates[  9500] train loss[0.52321] remaining[0:09:33]
05/07/2020 03:01:22 Task [ 1] updates[ 10000] train loss[0.50520] remaining[0:07:11]
05/07/2020 03:03:48 Task [ 1] updates[ 10500] train loss[0.48738] remaining[0:04:50]
05/07/2020 03:06:14 Task [ 3] updates[ 11000] train loss[0.47142] remaining[0:02:27]
05/07/2020 03:08:42 Task [ 2] updates[ 11500] train loss[0.45739] remaining[0:00:03]
predicting 0
05/07/2020 03:08:48 Task assin-ptbr-sts -- epoch 3 -- Dev Pearson: 77.554
05/07/2020 03:08:48 Task assin-ptbr-sts -- epoch 3 -- Dev MSE: 10.038
predicting 0
predicting 100
predicting 200
05/07/2020 03:08:59 [new test scores saved.]
predicting 0
05/07/2020 03:09:02 Task assin-ptbr-rte -- epoch 3 -- Dev F1MAC: 79.663
05/07/2020 03:09:02 Task assin-ptbr-rte -- epoch 3 -- Dev ACC: 89.400
predicting 0
predicting 100
predicting 200
05/07/2020 03:09:13 [new test scores saved.]
predicting 0
05/07/2020 03:09:16 Task assin-ptpt-sts -- epoch 3 -- Dev Pearson: 84.958
05/07/2020 03:09:16 Task assin-ptpt-sts -- epoch 3 -- Dev MSE: 10.606
predicting 0
predicting 100
predicting 200
05/07/2020 03:09:26 [new test scores saved.]
predicting 0
05/07/2020 03:09:29 Task assin2-rte -- epoch 3 -- Dev F1MAC: 94.796
05/07/2020 03:09:29 Task assin2-rte -- epoch 3 -- Dev ACC: 94.800
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 03:09:42 [new test scores saved.]
predicting 0
05/07/2020 03:09:45 Task assin-ptpt-rte -- epoch 3 -- Dev F1MAC: 76.429
05/07/2020 03:09:45 Task assin-ptpt-rte -- epoch 3 -- Dev ACC: 88.600
predicting 0
predicting 100
predicting 200
05/07/2020 03:09:56 [new test scores saved.]
predicting 0
05/07/2020 03:09:59 Task assin2-sts -- epoch 3 -- Dev Pearson: 91.302
05/07/2020 03:09:59 Task assin2-sts -- epoch 3 -- Dev MSE: 16.447
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 03:10:12 [new test scores saved.]
I0507 03:10:14.740205 140580425697024 model.py:278] model saved to /container/mt-dnn_port/output/mt-dnn_assin/bert_base/seed/2018/model_3.pt
05/07/2020 03:10:14 At epoch 4
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
05/07/2020 03:12:37 Task [ 4] updates[ 12000] train loss[0.44410] remaining[0:11:39]
05/07/2020 03:15:03 Task [ 1] updates[ 12500] train loss[0.43160] remaining[0:09:13]
05/07/2020 03:17:27 Task [ 5] updates[ 13000] train loss[0.41944] remaining[0:06:44]
05/07/2020 03:19:49 Task [ 5] updates[ 13500] train loss[0.40769] remaining[0:04:17]
05/07/2020 03:22:14 Task [ 5] updates[ 14000] train loss[0.39750] remaining[0:01:52]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
predicting 0
05/07/2020 03:24:08 Task assin-ptbr-sts -- epoch 4 -- Dev Pearson: 77.481
05/07/2020 03:24:08 Task assin-ptbr-sts -- epoch 4 -- Dev MSE: 10.038
predicting 0
predicting 100
predicting 200
05/07/2020 03:24:19 [new test scores saved.]
predicting 0
05/07/2020 03:24:22 Task assin-ptbr-rte -- epoch 4 -- Dev F1MAC: 81.989
05/07/2020 03:24:22 Task assin-ptbr-rte -- epoch 4 -- Dev ACC: 89.400
predicting 0
predicting 100
predicting 200
05/07/2020 03:24:33 [new test scores saved.]
predicting 0
05/07/2020 03:24:36 Task assin-ptpt-sts -- epoch 4 -- Dev Pearson: 84.958
05/07/2020 03:24:36 Task assin-ptpt-sts -- epoch 4 -- Dev MSE: 10.606
predicting 0
predicting 100
predicting 200
05/07/2020 03:24:46 [new test scores saved.]
predicting 0
05/07/2020 03:24:49 Task assin2-rte -- epoch 4 -- Dev F1MAC: 96.199
05/07/2020 03:24:49 Task assin2-rte -- epoch 4 -- Dev ACC: 96.200
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 03:25:02 [new test scores saved.]
predicting 0
05/07/2020 03:25:05 Task assin-ptpt-rte -- epoch 4 -- Dev F1MAC: 76.978
05/07/2020 03:25:05 Task assin-ptpt-rte -- epoch 4 -- Dev ACC: 88.800
predicting 0
predicting 100
predicting 200
05/07/2020 03:25:16 [new test scores saved.]
predicting 0
05/07/2020 03:25:19 Task assin2-sts -- epoch 4 -- Dev Pearson: 91.717
05/07/2020 03:25:19 Task assin2-sts -- epoch 4 -- Dev MSE: 16.447
predicting 0
predicting 100
predicting 200
predicting 300
05/07/2020 03:25:32 [new test scores saved.]
I0507 03:25:35.473141 140580425697024 model.py:278] model saved to /container/mt-dnn_port/output/mt-dnn_assin/bert_base/seed/2018/model_4.pt
rm: unrecognized option '--output_dir'
Try 'rm --help' for more information.

real	79m6.716s
user	71m22.843s
sys	7m7.655s
